{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "zYPnKxIhFGVJ",
   "metadata": {
    "id": "zYPnKxIhFGVJ"
   },
   "source": [
    "# Collaboration recommender system 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "x7McZwR_FRta",
   "metadata": {
    "id": "x7McZwR_FRta"
   },
   "source": [
    "## **Setting up environment**\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jX5i4Qjs7MIl",
   "metadata": {
    "id": "jX5i4Qjs7MIl"
   },
   "source": [
    "### **Package installation**\n",
    "\n",
    "Installing `torch` and `torch_geometric` libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "t4n7jKW9uiQE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t4n7jKW9uiQE",
    "outputId": "d501c056-f66b-487d-f655-e3fb97de55df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(os.environ['TORCH'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cD8tnTfC60X2",
   "metadata": {
    "id": "cD8tnTfC60X2"
   },
   "source": [
    "### **Loading libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5okfWmvKEI3Z",
   "metadata": {
    "id": "5okfWmvKEI3Z"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(\"../..\"))\n",
    "\n",
    "# PyTorch imports\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Embedding\n",
    "\n",
    "# PyTorch Geometric imports\n",
    "import torch_geometric\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric import EdgeIndex\n",
    "from torch_geometric.loader import LinkNeighborLoader, NeighborLoader\n",
    "from torch_geometric.nn import SAGEConv, HeteroConv, to_hetero, MIPSKNNIndex, Linear\n",
    "from torch_geometric.data import HeteroData, Batch\n",
    "from torch_geometric.nn.models.lightgcn import BPRLoss\n",
    "from torch_geometric.utils import structured_negative_sampling\n",
    "from torch_geometric.metrics import (\n",
    "    LinkPredPrecision,\n",
    "    LinkPredRecall,\n",
    "    LinkPredMAP,\n",
    "    LinkPredMRR,\n",
    "    LinkPredNDCG\n",
    "    )\n",
    "\n",
    "\n",
    "# Other imports\n",
    "import io\n",
    "import datetime\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "from box import Box\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from util.postgres import create_sqlalchemy_engine, query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "X6kGtZ7RD7Y9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X6kGtZ7RD7Y9",
    "outputId": "f8f52ea7-44e2-431a-e8a7-52419fc01381"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0+cpu\n",
      "2.7.0\n",
      "Device: 'cpu'\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(torch.__version__)\n",
    "print(torch_geometric.__version__)\n",
    "print(f\"Device: '{device}'\")\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bQ_xqBiFn97Q",
   "metadata": {
    "id": "bQ_xqBiFn97Q"
   },
   "source": [
    "### **Global variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9r1K6ezsn97Q",
   "metadata": {
    "id": "9r1K6ezsn97Q"
   },
   "outputs": [],
   "source": [
    "# -------------------- GLOBAL VARIABLES --------------------\n",
    "PATH_TO_CONFIG_FILE = '../../config.yaml'\n",
    "\n",
    "# -------------------- LOAD CONFIGURATION --------------------\n",
    "# Load the configuration file\n",
    "config = Box.from_yaml(filename=PATH_TO_CONFIG_FILE)\n",
    "\n",
    "num_recommendations = 10    # Number of recommendations\n",
    "num_train = 0.8             # Percentage of data used for training\n",
    "learning_rate = 1e-2        # Learning rate\n",
    "num_epochs = 20            # Number of epochs\n",
    "hidden_channels = 128       # Number of hidden channels\n",
    "\n",
    "target_edge_type = ('author', 'co_authors', 'author')\n",
    "target_node_type = 'author'\n",
    "\n",
    "pg_engine = create_sqlalchemy_engine(\n",
    "    username=config.POSTGRES.USERNAME,\n",
    "    password=config.POSTGRES.PASSWORD,\n",
    "    host=config.POSTGRES.HOST,\n",
    "    port=config.POSTGRES.PORT,\n",
    "    database=config.POSTGRES.DATABASE,\n",
    "    schema=config.POSTGRES.SCHEMA\n",
    ")\n",
    "batch_size = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ISUVX4hvFMKM",
   "metadata": {
    "id": "ISUVX4hvFMKM"
   },
   "source": [
    "## **Data preparation**\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PUmNU6hf75k7",
   "metadata": {
    "id": "PUmNU6hf75k7"
   },
   "source": [
    "### **Loading data**\n",
    "\n",
    "When loading the data, we take into account only the articles, where at least one author comes from the EUTOPIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9219071e-65c1-42ef-8a0d-aa8f827e9805",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37.7 ms, sys: 9.77 ms, total: 47.4 ms\n",
      "Wall time: 84.5 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>dummy_feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000-0001-6379-2381</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000-0001-7809-8050</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000-0001-8367-5465</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000-0001-8606-6825</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000-0001-8718-9819</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author_id  dummy_feature\n",
       "0  0000-0001-6379-2381              1\n",
       "1  0000-0001-7809-8050              1\n",
       "2  0000-0001-8367-5465              1\n",
       "3  0000-0001-8606-6825              1\n",
       "4  0000-0001-8718-9819              1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Get all authors data and value metrics about their collaboration\n",
    "author_query = f\"\"\"\n",
    "SELECT *\n",
    "FROM g_eucoht_node_author\n",
    "\"\"\"\n",
    "with pg_engine.connect() as conn:\n",
    "    author_df = query(conn=conn, query_str=author_query)\n",
    "\n",
    "conn.close()\n",
    "author_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f88d120f-8694-47c3-9592-c1a6fde00d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 770 ms, sys: 125 ms, total: 895 ms\n",
      "Wall time: 975 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23037324500</td>\n",
       "      <td>0013330732</td>\n",
       "      <td>20180206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6507696573</td>\n",
       "      <td>0013330732</td>\n",
       "      <td>20180206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000-0003-4842-5676</td>\n",
       "      <td>10.1002/aenm.201301688</td>\n",
       "      <td>20140101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14822457300</td>\n",
       "      <td>10.1002/cmdc.201402459</td>\n",
       "      <td>20141217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000-0001-7809-8050</td>\n",
       "      <td>10.1002/cplu.201402054</td>\n",
       "      <td>20140101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author_id              article_id      time\n",
       "0          23037324500              0013330732  20180206\n",
       "1           6507696573              0013330732  20180206\n",
       "2  0000-0003-4842-5676  10.1002/aenm.201301688  20140101\n",
       "3          14822457300  10.1002/cmdc.201402459  20141217\n",
       "4  0000-0001-7809-8050  10.1002/cplu.201402054  20140101"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Get all authors data and value metrics about their collaboration\n",
    "published_query = f\"\"\"\n",
    "SELECT *\n",
    "FROM g_eucoht_edge_publishes\n",
    "\"\"\"\n",
    "with pg_engine.connect() as conn:\n",
    "    published_df = query(conn=conn, query_str=published_query)\n",
    "\n",
    "conn.close()\n",
    "published_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e5129cd-4f87-4faa-b002-13ef6c74b3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 76.7 ms, sys: 10.9 ms, total: 87.6 ms\n",
      "Wall time: 112 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>co_author_id</th>\n",
       "      <th>time</th>\n",
       "      <th>eutopia_collaboration_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000-0001-8367-5465</td>\n",
       "      <td>0000-0001-9448-789X</td>\n",
       "      <td>20050101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000-0001-9448-789X</td>\n",
       "      <td>0000-0001-8367-5465</td>\n",
       "      <td>20050101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000-0003-3517-3780</td>\n",
       "      <td>6506321882</td>\n",
       "      <td>20120101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10040417200</td>\n",
       "      <td>8221262000</td>\n",
       "      <td>20090101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10040997700</td>\n",
       "      <td>18233779900</td>\n",
       "      <td>20091101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author_id         co_author_id      time  \\\n",
       "0  0000-0001-8367-5465  0000-0001-9448-789X  20050101   \n",
       "1  0000-0001-9448-789X  0000-0001-8367-5465  20050101   \n",
       "2  0000-0003-3517-3780           6506321882  20120101   \n",
       "3          10040417200           8221262000  20090101   \n",
       "4          10040997700          18233779900  20091101   \n",
       "\n",
       "   eutopia_collaboration_count  \n",
       "0                            0  \n",
       "1                            0  \n",
       "2                            0  \n",
       "3                            0  \n",
       "4                            0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Get all authors data and value metrics about their collaboration\n",
    "coauthored_query = f\"\"\"\n",
    "SELECT *\n",
    "FROM g_eucoht_edge_co_authors\n",
    "\"\"\"\n",
    "with pg_engine.connect() as conn:\n",
    "    coauthored_df = query(conn=conn, query_str=coauthored_query)\n",
    "\n",
    "conn.close()\n",
    "coauthored_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2344da7a-a59f-42a0-80e7-c37a9ac91024",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows fetched 10000 for batch 0\n",
      "Rows fetched 10000 for batch 1\n",
      "Rows fetched 10000 for batch 2\n",
      "Rows fetched 10000 for batch 3\n",
      "Rows fetched 10000 for batch 4\n",
      "Rows fetched 10000 for batch 5\n",
      "CPU times: user 32.3 s, sys: 9.58 s, total: 41.9 s\n",
      "Wall time: 1min 3s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>article_citation_normalized_count</th>\n",
       "      <th>is_eutopia_collaboration</th>\n",
       "      <th>collaboration_novelty_index</th>\n",
       "      <th>article_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84865405594</td>\n",
       "      <td>20.42</td>\n",
       "      <td>0</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>[0.004589761607348919, 0.02756412886083126, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84880929267</td>\n",
       "      <td>1.37</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500070</td>\n",
       "      <td>[0.010607256554067135, 0.027150079607963562, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77952382135</td>\n",
       "      <td>4.29</td>\n",
       "      <td>0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>[-0.006951452698558569, -0.0008734843577258289...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77954866153</td>\n",
       "      <td>6.23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>[0.005069693550467491, 0.007222142070531845, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85030783799</td>\n",
       "      <td>1.42</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>[-0.01370143610984087, 0.01628061570227146, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    article_id article_citation_normalized_count  is_eutopia_collaboration  \\\n",
       "0  84865405594                             20.42                         0   \n",
       "1  84880929267                              1.37                         0   \n",
       "2  77952382135                              4.29                         0   \n",
       "3  77954866153                              6.23                         0   \n",
       "4  85030783799                              1.42                         0   \n",
       "\n",
       "   collaboration_novelty_index  \\\n",
       "0                     0.861111   \n",
       "1                     0.500070   \n",
       "2                     3.000000   \n",
       "3                     0.770833   \n",
       "4                     2.000000   \n",
       "\n",
       "                                   article_embedding  \n",
       "0  [0.004589761607348919, 0.02756412886083126, -0...  \n",
       "1  [0.010607256554067135, 0.027150079607963562, -...  \n",
       "2  [-0.006951452698558569, -0.0008734843577258289...  \n",
       "3  [0.005069693550467491, 0.007222142070531845, -...  \n",
       "4  [-0.01370143610984087, 0.01628061570227146, 0....  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "with pg_engine.raw_connection().cursor() as cur:\n",
    "    article_query = f\"\"\"\n",
    "    SELECT article_id,\n",
    "           article_citation_normalized_count,\n",
    "           is_eutopia_collaboration,\n",
    "           collaboration_novelty_index,\n",
    "           article_embedding\n",
    "    FROM g_eucoht_node_article\n",
    "    \"\"\"\n",
    "    cur.execute(article_query)\n",
    "    # Initialize the Polars DataFrame\n",
    "    article_df_polars: pl.DataFrame = pl.DataFrame()\n",
    "    ix = 0\n",
    "    # Fetch in chunks\n",
    "    while True:\n",
    "        rows = cur.fetchmany(size=batch_size)\n",
    "        if not rows:\n",
    "            break\n",
    "        # Append the rows to the Polars DataFrame\n",
    "        df_chunk = pl.DataFrame(rows, schema=[\n",
    "            \"article_id\", \n",
    "            \"article_citation_normalized_count\",\n",
    "            \"is_eutopia_collaboration\",\n",
    "            \"collaboration_novelty_index\",\n",
    "            \"article_embedding\"\n",
    "        ], orient=\"row\")\n",
    "    \n",
    "        # Concatenate chunk with the master DataFrame\n",
    "        article_df_polars = pl.concat([article_df_polars, df_chunk], how=\"vertical\")\n",
    "        print(f\"Rows fetched {batch_size} for batch {ix}\")\n",
    "        ix += 1\n",
    "\n",
    "article_df = article_df_polars.to_pandas()\n",
    "article_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dZW9dtfeuhKT",
   "metadata": {
    "id": "dZW9dtfeuhKT"
   },
   "source": [
    "### Contiguous unique identifier for node: **author**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "S3vkAApdE7M9",
   "metadata": {
    "id": "S3vkAApdE7M9"
   },
   "outputs": [],
   "source": [
    "# Author: Map each unique MD5 hash to a contiguous unique integer ID\n",
    "unique_authors = author_df['author_id'].unique()\n",
    "author_id_map = {author: i for i, author in enumerate(unique_authors)}\n",
    "author_sid_map = {y: x for x, y in author_id_map.items()}\n",
    "# ---> Adjust all dataframes\n",
    "author_df['author_node_id'] = author_df['author_id'].map(author_id_map)\n",
    "published_df['author_node_id'] = published_df['author_id'].map(author_id_map)\n",
    "coauthored_df['author_node_id'] = coauthored_df['author_id'].map(author_id_map)\n",
    "coauthored_df['co_author_node_id'] = coauthored_df['co_author_id'].map(author_id_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sLnxwKwBur9Z",
   "metadata": {
    "id": "sLnxwKwBur9Z"
   },
   "source": [
    "### Contiguous unique identifier for node: **article**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "BUgz5_tQuyQl",
   "metadata": {
    "id": "BUgz5_tQuyQl",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Article: Map each unique MD5 hash to a contiguous unique integer ID\n",
    "unique_articles = published_df['article_id'].unique()\n",
    "article_id_map = {article: i for i, article in enumerate(unique_articles)}\n",
    "article_sid_map = {y: x for x, y in article_id_map.items()}\n",
    "# ---> Adjust all dataframes\n",
    "article_df['article_node_id'] = article_df['article_id'].map(article_id_map)\n",
    "published_df['article_node_id'] = published_df['article_id'].map(article_id_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aZQQpLqCFeGK",
   "metadata": {
    "id": "aZQQpLqCFeGK"
   },
   "source": [
    "## **Heterogeneous graph creation**\n",
    "First of all, we prepare the node features for articles. We first sort the article dataframe by node ID. We know that we have unique values in the article dataframe, i.e. one row per article and we can just sort it. Otherwise, we would need to create a unique mapping between article features and articles themselves. The sorting needs to match the node index that we will create later. After that, we also need to set up correct type (specifically, convert Pandas Int64 to int64, but we go for the lazy version and just convert all features to float64). At last, we exclude the `ARTICLE_SID` and `ARTICLE_NODE_ID` columns, because Torch can't work with strings.\n",
    "\n",
    "**TODO:**\n",
    "- Think about only including \"valuable\" partnerships/edges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KHk6LU_su7-S",
   "metadata": {
    "id": "KHk6LU_su7-S"
   },
   "source": [
    "### Matrix X for node: **article**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e5ke0kkvLpg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7e5ke0kkvLpg",
    "outputId": "902ce4d6-492c-41cc-e1e5-76ef8a70bede"
   },
   "outputs": [],
   "source": [
    "# Article X\n",
    "# Sort article dataframe\n",
    "sorted_article_df = article_df.sort_values(by='article_node_id')\n",
    "article_x_columns = list(filter(lambda x: x not in ('article_id', 'article_node_id', 'article_embedding'), sorted_article_df.columns))\n",
    "\n",
    "# Convert EMBEDDING_TENSOR_DATA to proper format\n",
    "embedding_tensor = np.stack(sorted_article_df['article_embedding'].values)\n",
    "embedding_tensor = torch.tensor(embedding_tensor, dtype=torch.float)\n",
    "\n",
    "# Convert types\n",
    "article_x = sorted_article_df[article_x_columns].astype('float32').values\n",
    "\n",
    "# Append embedding_tensor to article_x\n",
    "article_x = np.concatenate((article_x, embedding_tensor), axis=1)\n",
    "\n",
    "# Normalize X using std scaler\n",
    "article_x = StandardScaler().fit_transform(article_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XBN1GHNyvLPP",
   "metadata": {
    "id": "XBN1GHNyvLPP"
   },
   "source": [
    "### Matrix X for node: **author**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "tg-GzYGtErQx",
   "metadata": {
    "id": "tg-GzYGtErQx"
   },
   "outputs": [],
   "source": [
    "# Author X\n",
    "# Sort author dataframe\n",
    "sorted_author_df = author_df.sort_values(by='author_node_id')\n",
    "# Exclude columns AUTHOR_SID, AUTHOR_NODE_ID\n",
    "author_x_columns = list(filter(lambda x: x not in ('author_id', 'author_node_id'), sorted_author_df.columns))\n",
    "# Convert types\n",
    "author_x = sorted_author_df[author_x_columns].astype('float32').values\n",
    "\n",
    "# Normalize X using std scaler\n",
    "author_x = StandardScaler().fit_transform(author_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8mbn1x9AvWA-",
   "metadata": {
    "id": "8mbn1x9AvWA-"
   },
   "source": [
    "### Edge index for edge: **(author, publishes, article)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dLiq1tZviaE",
   "metadata": {
    "id": "8dLiq1tZviaE"
   },
   "outputs": [],
   "source": [
    "# Add edge index: for edges corresponding to authors publishing articles (author to article connection)\n",
    "author_node_ids = torch.from_numpy(published_df['author_node_id'].values)\n",
    "article_node_ids = torch.from_numpy(published_df['article_node_id'].values)\n",
    "edge_index_publishes = torch.stack([author_node_ids, article_node_ids], dim=0)\n",
    "edge_time_publishes = torch.from_numpy(np.array(published_df['time'].values.astype('int64')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6oizfRnsvjYx",
   "metadata": {
    "id": "6oizfRnsvjYx"
   },
   "source": [
    "### Edge index for edge: **(author, co_authors, author)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "UqXKby3KFhqx",
   "metadata": {
    "id": "UqXKby3KFhqx"
   },
   "outputs": [],
   "source": [
    "# Add edge index: for edges corresponding to authors co-authoring articles (author to author connection)\n",
    "author_node_ids = torch.from_numpy(coauthored_df['author_node_id'].values)\n",
    "coauthor_node_ids = torch.from_numpy(coauthored_df['co_author_node_id'].values)\n",
    "edge_index_co_authors = torch.stack([author_node_ids, coauthor_node_ids], dim=0)\n",
    "edge_time_co_authors = torch.from_numpy(np.array(coauthored_df['time'].values.astype('int64')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mi3u5Xx0v5DB",
   "metadata": {
    "id": "mi3u5Xx0v5DB"
   },
   "source": [
    "### Data object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PXBEBlOCFn34",
   "metadata": {
    "id": "PXBEBlOCFn34"
   },
   "source": [
    "After generating the initial node feature Numpy array, we create an instance of `HeteroData` class with two types of nodes corresponding to authors and articles and an edge denoting authors publishing articles.\n",
    "\n",
    "*Note: We also need to make sure to add the reverse edges from authors to aritcles in order to let a GNN be able to pass messages in both directions. We can leverage the `T.ToUndirected()` transform for this from PyG.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0h15yaEpFo8x",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0h15yaEpFo8x",
    "outputId": "ced758f7-4fdf-4acb-b1d7-46f103116f67"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  article={\n",
       "    node_id=[55076],\n",
       "    x=[55076, 771],\n",
       "  },\n",
       "  author={\n",
       "    node_id=[7734],\n",
       "    x=[7734, 1],\n",
       "  },\n",
       "  (author, publishes, article)={\n",
       "    edge_index=[2, 124874],\n",
       "    time=[124874],\n",
       "  },\n",
       "  (author, co_authors, author)={\n",
       "    edge_index=[2, 28210],\n",
       "    time=[28210],\n",
       "  },\n",
       "  (article, rev_publishes, author)={\n",
       "    edge_index=[2, 124874],\n",
       "    time=[124874],\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = HeteroData()\n",
    "\n",
    "# Save node indices:\n",
    "data[\"article\"].node_id = torch.arange(len(unique_articles))\n",
    "data[\"author\"].node_id = torch.arange(len(unique_authors))\n",
    "# Add edge 'published'\n",
    "data[\"author\", \"publishes\", \"article\"].edge_index = edge_index_publishes\n",
    "data[\"author\", \"publishes\", \"article\"].time = edge_time_publishes\n",
    "# Add edge 'co_authors'\n",
    "data[('author', 'co_authors', 'author')].edge_index = edge_index_co_authors\n",
    "data[('author', 'co_authors', 'author')].time = edge_time_co_authors\n",
    "\n",
    "# Set X for article\n",
    "data[\"article\"].x = torch.from_numpy(article_x)\n",
    "# Set X for author\n",
    "data[\"author\"].x = torch.from_numpy(author_x)\n",
    "\n",
    "# Reverse edges\n",
    "data = T.ToUndirected(reduce='min')(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "tg8fjdOJn3QS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tg8fjdOJn3QS",
    "outputId": "4164664b-14bc-49f3-95bb-95e7c34de885"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'article': tensor([[-0.1702, -0.1677, -0.0535,  ..., -1.5174,  0.4311,  1.0342],\n",
       "         [ 0.7226, -0.1677, -0.1208,  ..., -0.0900,  2.0186,  0.2434],\n",
       "         [ 0.2148, -0.1677, -0.1208,  ...,  0.1781,  1.6704, -0.6084],\n",
       "         ...,\n",
       "         [-0.1976, -0.1677,  0.0035,  ..., -0.7453, -0.5125, -0.5808],\n",
       "         [-0.1976, -0.1677, -0.1829,  ...,  0.4680,  0.8709,  1.5607],\n",
       "         [-0.1976, -0.1677, -0.0820,  ...,  0.6162,  0.6727,  0.2975]]),\n",
       " 'author': tensor([[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dQtlX8gLwj77",
   "metadata": {
    "id": "dQtlX8gLwj77"
   },
   "source": [
    "## Heterogeneous graph batching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_vuTOx9IxDOs",
   "metadata": {
    "id": "_vuTOx9IxDOs"
   },
   "source": [
    "###  Split data to train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "u-fOB4GRYCC4",
   "metadata": {
    "id": "u-fOB4GRYCC4"
   },
   "outputs": [],
   "source": [
    "edge_types = data.metadata()[1]\n",
    "\n",
    "time = data[target_edge_type].time\n",
    "perm = time.argsort()\n",
    "# Find minimum time in `co_authors` edge that still resides in test set\n",
    "test_min_time = time[perm[int(num_train * perm.numel()):]].min()\n",
    "\n",
    "for edge_type in edge_types:\n",
    "  # Define the training dataset for all edge types\n",
    "  time = data[edge_type].time\n",
    "  data[edge_type].train_mask = time < test_min_time\n",
    "  data[edge_type].train_edge_index = data[edge_type].edge_index[:, data[edge_type].train_mask]\n",
    "  data[edge_type].train_edge_time = time[data[edge_type].train_mask]\n",
    "\n",
    "data.train_edge_index_dict = {edge_type: data[edge_type].train_edge_index for edge_type in edge_types}\n",
    "\n",
    "# Add test dataset for `co_authors` edge type\n",
    "data[target_edge_type].test_mask = data[target_edge_type].time >= test_min_time\n",
    "data[target_edge_type].test_pos_edge_index = data[target_edge_type].edge_index[:, data[target_edge_type].test_mask]\n",
    "data[target_edge_type].test_edge_time = data[target_edge_type].time[data[target_edge_type].test_mask]\n",
    "\n",
    "\n",
    "# Negative sampling\n",
    "test_neg_edge_index_i, test_neg_edge_index_j, test_neg_edge_index_k = structured_negative_sampling(\n",
    "    edge_index=data[target_edge_type].test_pos_edge_index,\n",
    "    num_nodes=data[target_node_type].num_nodes)\n",
    "test_neg_edge_index = torch.stack([test_neg_edge_index_i, test_neg_edge_index_k], dim=0)\n",
    "# Add negative samples to test data\n",
    "data[target_edge_type].test_neg_edge_index = test_neg_edge_index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "D52ZyYck73fh",
   "metadata": {
    "id": "D52ZyYck73fh"
   },
   "source": [
    "### Data loader (mini-batching)\n",
    "\n",
    "After splitting the data, we need to take into account that we are dealing with very large graphs. A simple load of data to GPU will already return `CUDA out of memory` exception. Hence, we use mini-batching to appropriately split the edges (regardless if we are in training, testing or validation phase). This process will separate the large graph into multiple smaller graphs and process them independently, thus fixing the out-of-memory exceptions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04vUews17zy8",
   "metadata": {
    "id": "04vUews17zy8"
   },
   "source": [
    "## Model training\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kmt2IwuC8C-S",
   "metadata": {
    "id": "kmt2IwuC8C-S"
   },
   "source": [
    "### Model definition\n",
    "\n",
    "Our model consists of two parts, first we must encode our nodes using the message passing algorithm exploiting both (author, co-authors, author) and (author, publishes, article) edges and corresponding node features. The second part decodes the edges that the model outputs as its prediction using two simple, fully-connected, linear layers.\n",
    "\n",
    "**TODO:**\n",
    "- Promote EUTOPIA-an collaborations or even restrict to EUTOPIA-an collaborations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "FwVf1kDPLnFH",
   "metadata": {
    "id": "FwVf1kDPLnFH"
   },
   "outputs": [],
   "source": [
    "from typing import Optional, Union\n",
    "from torch_geometric.nn import HANConv, HGTConv\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch.nn import Embedding, ModuleList\n",
    "from torch.nn.modules.loss import _Loss\n",
    "\n",
    "from torch_geometric.nn.conv import GATv2Conv,GCNConv, SAGEConv\n",
    "from torch_geometric.typing import Adj, OptTensor\n",
    "from torch_geometric.utils import is_sparse, to_edge_index\n",
    "from torch_geometric.nn.models.lightgcn import BPRLoss\n",
    "\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels: int, \n",
    "                 num_layers: int = 4):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "        # Define multiple HANConv layers:\n",
    "        # self.conv_layers = ModuleList([\n",
    "        #     HANConv(\n",
    "        #         in_channels=(-1),\n",
    "        #         out_channels=hidden_channels,\n",
    "        #         metadata=data.metadata(),\n",
    "        #         heads=4,\n",
    "        #         dropout=0.5\n",
    "        #     )\n",
    "        #     for i in range(self.num_layers)\n",
    "        # ])\n",
    "\n",
    "        #Define multiple HANConv layers:\n",
    "        self.conv_layers = ModuleList([\n",
    "            HGTConv(\n",
    "                in_channels=(-1),\n",
    "                out_channels=hidden_channels,\n",
    "                metadata=data.metadata(),\n",
    "                heads=4\n",
    "            )\n",
    "            for i in range(self.num_layers)\n",
    "        ])\n",
    "\n",
    "\n",
    "        \n",
    "        # Linear layers (for skips)\n",
    "        self.linear_layers = dict(\n",
    "            author=ModuleList([\n",
    "                Linear(-1, hidden_channels)\n",
    "                for i in range(self.num_layers)\n",
    "            ]),\n",
    "            article=ModuleList([\n",
    "                Linear(-1, hidden_channels)\n",
    "                for i in range(self.num_layers)\n",
    "                ])\n",
    "        )\n",
    "        \n",
    "        self.bn_layers = dict(\n",
    "            author=ModuleList([\n",
    "                torch.nn.BatchNorm1d(hidden_channels)\n",
    "                for i in range(self.num_layers)\n",
    "            ]),\n",
    "            article=ModuleList([\n",
    "                torch.nn.BatchNorm1d(hidden_channels)\n",
    "                for i in range(self.num_layers)\n",
    "                ])\n",
    "        )\n",
    "\n",
    "        # Initialize the alpha\n",
    "        alpha = torch.ones(self.num_layers + 1) / (self.num_layers + 1)\n",
    "\n",
    "        # Register alpha as a parameter if you want it to be learnable:\n",
    "        self.alpha = alpha # nn.Parameter(alpha, requires_grad=True)   \n",
    "\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        # out_dict = {\n",
    "        #     ntype: torch.zeros(x.shape[0], self.conv_layers[0].out_channels, device=x.device)\n",
    "        #     for ntype, x in x_dict.items()\n",
    "        # }\n",
    "        \n",
    "        # Keep track of current hidden states\n",
    "        h_dict = x_dict\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            # Apply HANConv\n",
    "            new_h_dict = self.conv_layers[i](h_dict, edge_index_dict)\n",
    "        \n",
    "            # Add skip connection\n",
    "            for ntype in new_h_dict:\n",
    "                new_h_dict[ntype] = new_h_dict[ntype] + self.linear_layers[ntype][i](h_dict[ntype])\n",
    "        \n",
    "            # BatchNorm\n",
    "            for ntype in new_h_dict:\n",
    "                new_h_dict[ntype] = self.bn_layers[ntype][i](new_h_dict[ntype])\n",
    "\n",
    "            # Accumulate in out_dict with alpha weighting\n",
    "            # for ntype in out_dict:\n",
    "            #     out_dict[ntype] += self.alpha[i] * new_h_dict[ntype]\n",
    "        \n",
    "            # Update hidden state for next layer\n",
    "            h_dict = new_h_dict\n",
    "        \n",
    "        # return out_dict\n",
    "        return h_dict\n",
    "\n",
    "\n",
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, z, edge_label_index):\n",
    "        out_src = z[edge_label_index[0]]\n",
    "        out_dst = z[edge_label_index[1]]\n",
    "\n",
    "        # Calculate the dot product\n",
    "        return (out_src * out_dst).sum(dim=-1)\n",
    "\n",
    "class CollaborationRecommender(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 hidden_channels: int,\n",
    "                 k: int,\n",
    "                 alpha: Optional[Union[float, Tensor]] = None,\n",
    "                 num_layers: int = 4):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.k = k\n",
    "\n",
    "        self.encoder = Encoder(hidden_channels=hidden_channels, num_layers=num_layers)\n",
    "        self.decoder = Decoder()\n",
    "\n",
    "\n",
    "    def forward(self,\n",
    "                x_dict,\n",
    "                edge_index_dict,\n",
    "                edge_label_index: OptTensor = None):\n",
    "\n",
    "        # Encode authors\n",
    "        z_dict = self.encoder(x_dict, edge_index_dict)\n",
    "        z = z_dict['author']\n",
    "        # Decode edges\n",
    "        return self.decoder(z, edge_label_index)\n",
    "\n",
    "    def recommend(self,\n",
    "                  x_dict,\n",
    "                  edge_index_dict,\n",
    "                  author_sid: str,\n",
    "                  k: int = 10):\n",
    "\n",
    "        # Get all embeddings\n",
    "        out_src = out_dst = self.encoder(x_dict, edge_index_dict)\n",
    "\n",
    "        # Get the author id\n",
    "        author_id = author_id_map[author_sid]\n",
    "        # Get the author embedding\n",
    "        out_src = out_src[author_id]\n",
    "\n",
    "        # Calculate the dot product\n",
    "        pred = out_src @ out_dst.t()\n",
    "        # Get the top k recommendations\n",
    "        top_index = pred.topk(k, dim=-1, sorted=True).indices\n",
    "\n",
    "        # Decode top k recommendations to author SIDs\n",
    "        top_author_sids = [author_sid_map[int(i)] for i in top_index]\n",
    "\n",
    "        return top_author_sids\n",
    "\n",
    "\n",
    "    def recommendation_loss(self,\n",
    "                            x_dict,\n",
    "                            edge_index_dict,\n",
    "                            pos_edge_rank,\n",
    "                            neg_edge_rank,\n",
    "                            node_id: Optional[Tensor] = None,\n",
    "                            lambda_reg: float = 1e-4):\n",
    "        loss_fn = BPRLoss(lambda_reg)\n",
    "        # Get the embedding\n",
    "        z_dict = self.encoder(x_dict, edge_index_dict)\n",
    "        emb = z_dict['author']\n",
    "        # Get the loss\n",
    "        emb = emb if node_id is None else emb[node_id]\n",
    "        return loss_fn(pos_edge_rank, neg_edge_rank, emb)\n",
    "\n",
    "\n",
    "model = CollaborationRecommender(hidden_channels=64,\n",
    "                                 num_layers = 3,\n",
    "                                 k=num_recommendations).to(device)\n",
    "\n",
    "# Transfer to device\n",
    "data = data.to(device)\n",
    "optimizer = torch.optim.AdamW(params=model.parameters(), lr=5e-3)\n",
    "# optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='min', factor=0.5, patience=4)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hfuXSrL68FXZ",
   "metadata": {
    "id": "hfuXSrL68FXZ",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Helper functions for training and evaluation\n",
    "\n",
    "Our model is then trained through a number of epochs, where in each epoch we perform mini-batching to avoid memory issues on GPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "JNK2LtWgdxLY",
   "metadata": {
    "id": "JNK2LtWgdxLY"
   },
   "outputs": [],
   "source": [
    "import pytest\n",
    "from torch_geometric.metrics.link_pred import LinkPredMetric\n",
    "class LinkPredHitRate(LinkPredMetric):\n",
    "    higher_is_better: bool = True\n",
    "\n",
    "    def _compute(self, pred_isin_mat: Tensor, y_count: Tensor) -> Tensor:\n",
    "        return pred_isin_mat.sum(dim=-1) >= 1\n",
    "\n",
    "def test_hit_rate():\n",
    "    pred_mat = torch.tensor([[1, 0], [1, 2], [0, 2], [0, 1]])\n",
    "    edge_label_index = torch.tensor([[0, 0, 2, 2, 3], [0, 1, 2, 1, 2]])\n",
    "\n",
    "    metric = LinkPredHitRate(k=2)\n",
    "    metric.update(pred_mat, edge_label_index)\n",
    "    result = metric.compute()\n",
    "\n",
    "    assert result == pytest.approx((2) / 3)\n",
    "\n",
    "test_hit_rate()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    # Fetch existing graph edges as positive samples\n",
    "    pos_edge_index = data[target_edge_type].train_edge_index\n",
    "    # Perform structured negative sampling, meaning that for every positive sample,\n",
    "    # there will be another negative sample at the same index/position\n",
    "    # - this structure is expected in BPR loss calculation\n",
    "    neg_edge_index_i, neg_edge_index_j, neg_edge_index_k = structured_negative_sampling(\n",
    "        edge_index=pos_edge_index,\n",
    "        num_nodes=data[target_node_type].num_nodes)\n",
    "    # Structure negative sampling returns both positive and negative edges, so\n",
    "    # we need to concatenate appropriate nodes to get the negative edges\n",
    "    neg_edge_index = torch.stack([neg_edge_index_i, neg_edge_index_k], dim=0)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Concatenate edge label indices into a single edge label index\n",
    "    edge_label_index = torch.cat([\n",
    "        pos_edge_index,\n",
    "        neg_edge_index,\n",
    "    ], dim=1)\n",
    "\n",
    "    pos_edge_rank, neg_edge_rank = model(x_dict=data.x_dict,\n",
    "                                         edge_index_dict=data.train_edge_index_dict,\n",
    "                                         edge_label_index=edge_label_index).chunk(2)\n",
    "\n",
    "    # Calculate BPR loss\n",
    "    loss = model.recommendation_loss(x_dict=data.x_dict,\n",
    "                                     edge_index_dict=data.train_edge_index_dict,\n",
    "                                     pos_edge_rank=pos_edge_rank,\n",
    "                                     neg_edge_rank=neg_edge_rank,\n",
    "                                     node_id=edge_label_index.unique())\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    total_loss = float(loss) * pos_edge_rank.numel()\n",
    "    total_examples = pos_edge_rank.numel()\n",
    "\n",
    "    # Cleanup\n",
    "    del pos_edge_rank, neg_edge_rank\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return total_loss / total_examples\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "\n",
    "    pos_edge_index = data[target_edge_type].test_pos_edge_index\n",
    "    neg_edge_index = data[target_edge_type].test_neg_edge_index\n",
    "\n",
    "    # Concatenate edge label indices into a single edge label index\n",
    "    edge_label_index = torch.cat([\n",
    "        pos_edge_index,\n",
    "        neg_edge_index,\n",
    "    ], dim=1)\n",
    "\n",
    "    # We encode the training edge index to get the embeddings based on the training graph\n",
    "    # structure and then use those embeddings to predict unseen edges\n",
    "    # TODO: Check if this makes sense\n",
    "    pos_edge_rank, neg_edge_rank = model(x_dict=data.x_dict,\n",
    "                                         edge_index_dict=data.train_edge_index_dict,\n",
    "                                         edge_label_index=edge_label_index).chunk(2)\n",
    "\n",
    "    # Calculate BPR loss\n",
    "    loss = model.recommendation_loss(x_dict=data.x_dict,\n",
    "                                     edge_index_dict=data.train_edge_index_dict,\n",
    "                                     pos_edge_rank=pos_edge_rank,\n",
    "                                     neg_edge_rank=neg_edge_rank,\n",
    "                                     node_id=edge_label_index.unique())\n",
    "\n",
    "    total_loss = float(loss) * pos_edge_rank.numel()\n",
    "    total_examples = pos_edge_rank.numel()\n",
    "\n",
    "    # Cleanup\n",
    "    del pos_edge_rank, neg_edge_rank\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return total_loss / total_examples\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(k:int=20):\n",
    "    model.eval()\n",
    "    z_dict = model.encoder(data.x_dict, data.train_edge_index_dict)\n",
    "    embs = z_dict[target_node_type].to(device)\n",
    "\n",
    "    result = {\n",
    "        'precision@k': LinkPredPrecision(k=k).to(device),\n",
    "        'recall@k': LinkPredRecall(k=k).to(device),\n",
    "        'map@k': LinkPredMAP(k=k).to(device),\n",
    "        'mrr@k': LinkPredMRR(k=k).to(device),\n",
    "        'ndcg@k': LinkPredNDCG(k=k).to(device),\n",
    "        'hit_rate@k': LinkPredHitRate(k=k).to(device)\n",
    "        }\n",
    "\n",
    "    # Calculate distance between embeddings\n",
    "    logits = embs @ embs.T\n",
    "\n",
    "    # Exclude training edges\n",
    "    logits[data[target_edge_type].train_edge_index[0], data[target_edge_type].train_edge_index[1]] = float('-inf')\n",
    "\n",
    "    # Gather ground truth data\n",
    "    ground_truth = data[target_edge_type].test_pos_edge_index\n",
    "\n",
    "    # Get top-k recommendations for each node\n",
    "    top_k_index = torch.topk(logits, k=k, dim=1).indices\n",
    "\n",
    "    # Update performance metrics\n",
    "    for metric in result.keys():\n",
    "      result[metric].update(\n",
    "          pred_index_mat=top_k_index,\n",
    "          edge_label_index=ground_truth)\n",
    "\n",
    "    # Cleanup\n",
    "    del embs, logits, ground_truth, top_k_index\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18aa3757-32e2-463e-8cf1-a459d05f6093",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "NQS0tN81GTEF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NQS0tN81GTEF",
    "outputId": "45012f53-fe8e-4b9b-c236-8e12e6b9dbeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1.0000, train_loss_bpr: 0.2924, test_loss_bpr: 2.7962, precision@k: 0.0068, recall@k: 0.0105, map@k: 0.0052, mrr@k: 0.0198, ndcg@k: 0.0105, hit_rate@k: 0.0434\n",
      "epoch: 2.0000, train_loss_bpr: 0.3093, test_loss_bpr: 2.8261, precision@k: 0.0079, recall@k: 0.0139, map@k: 0.0060, mrr@k: 0.0227, ndcg@k: 0.0123, hit_rate@k: 0.0551\n",
      "epoch: 3.0000, train_loss_bpr: 0.1555, test_loss_bpr: 2.7219, precision@k: 0.0098, recall@k: 0.0130, map@k: 0.0074, mrr@k: 0.0244, ndcg@k: 0.0137, hit_rate@k: 0.0543\n",
      "epoch: 4.0000, train_loss_bpr: 0.1269, test_loss_bpr: 2.8473, precision@k: 0.0114, recall@k: 0.0194, map@k: 0.0092, mrr@k: 0.0267, ndcg@k: 0.0168, hit_rate@k: 0.0584\n",
      "epoch: 5.0000, train_loss_bpr: 0.1022, test_loss_bpr: 3.0128, precision@k: 0.0122, recall@k: 0.0198, map@k: 0.0102, mrr@k: 0.0276, ndcg@k: 0.0180, hit_rate@k: 0.0593\n",
      "epoch: 6.0000, train_loss_bpr: 0.0792, test_loss_bpr: 3.1838, precision@k: 0.0114, recall@k: 0.0202, map@k: 0.0095, mrr@k: 0.0257, ndcg@k: 0.0172, hit_rate@k: 0.0584\n",
      "epoch: 7.0000, train_loss_bpr: 0.0747, test_loss_bpr: 3.3320, precision@k: 0.0109, recall@k: 0.0178, map@k: 0.0092, mrr@k: 0.0246, ndcg@k: 0.0163, hit_rate@k: 0.0568\n",
      "epoch: 8.0000, train_loss_bpr: 0.0687, test_loss_bpr: 3.3670, precision@k: 0.0106, recall@k: 0.0191, map@k: 0.0092, mrr@k: 0.0237, ndcg@k: 0.0163, hit_rate@k: 0.0584\n",
      "epoch: 9.0000, train_loss_bpr: 0.0529, test_loss_bpr: 3.3811, precision@k: 0.0132, recall@k: 0.0211, map@k: 0.0094, mrr@k: 0.0264, ndcg@k: 0.0180, hit_rate@k: 0.0826\n",
      "epoch: 10.0000, train_loss_bpr: 0.0473, test_loss_bpr: 3.3813, precision@k: 0.0144, recall@k: 0.0215, map@k: 0.0096, mrr@k: 0.0266, ndcg@k: 0.0190, hit_rate@k: 0.0826\n",
      "epoch: 11.0000, train_loss_bpr: 0.0422, test_loss_bpr: 3.3921, precision@k: 0.0156, recall@k: 0.0212, map@k: 0.0100, mrr@k: 0.0272, ndcg@k: 0.0199, hit_rate@k: 0.0818\n",
      "epoch: 12.0000, train_loss_bpr: 0.0442, test_loss_bpr: 3.4048, precision@k: 0.0157, recall@k: 0.0227, map@k: 0.0110, mrr@k: 0.0311, ndcg@k: 0.0215, hit_rate@k: 0.0818\n",
      "epoch: 13.0000, train_loss_bpr: 0.0456, test_loss_bpr: 3.4248, precision@k: 0.0156, recall@k: 0.0241, map@k: 0.0107, mrr@k: 0.0312, ndcg@k: 0.0214, hit_rate@k: 0.0851\n",
      "epoch: 14.0000, train_loss_bpr: 0.0499, test_loss_bpr: 3.4353, precision@k: 0.0156, recall@k: 0.0234, map@k: 0.0103, mrr@k: 0.0310, ndcg@k: 0.0210, hit_rate@k: 0.0868\n",
      "epoch: 15.0000, train_loss_bpr: 0.0380, test_loss_bpr: 3.4461, precision@k: 0.0154, recall@k: 0.0235, map@k: 0.0096, mrr@k: 0.0265, ndcg@k: 0.0199, hit_rate@k: 0.0876\n",
      "epoch: 16.0000, train_loss_bpr: 0.0417, test_loss_bpr: 3.4529, precision@k: 0.0157, recall@k: 0.0240, map@k: 0.0104, mrr@k: 0.0311, ndcg@k: 0.0212, hit_rate@k: 0.0868\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[52], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m,  \u001B[38;5;241m100\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m      3\u001B[0m     train_loss \u001B[38;5;241m=\u001B[39m train()\n\u001B[0;32m----> 4\u001B[0m     test_loss \u001B[38;5;241m=\u001B[39m \u001B[43mtest\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m     scheduler\u001B[38;5;241m.\u001B[39mstep(test_loss)\n\u001B[1;32m      6\u001B[0m     eval_result \u001B[38;5;241m=\u001B[39m evaluate(k\u001B[38;5;241m=\u001B[39mnum_recommendations)\n",
      "File \u001B[0;32m~/eutopia-colllaboration/ecr-recommender/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    114\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    115\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 116\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[19], line 83\u001B[0m, in \u001B[0;36mtest\u001B[0;34m()\u001B[0m\n\u001B[1;32m     75\u001B[0m edge_label_index \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat([\n\u001B[1;32m     76\u001B[0m     pos_edge_index,\n\u001B[1;32m     77\u001B[0m     neg_edge_index,\n\u001B[1;32m     78\u001B[0m ], dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     80\u001B[0m \u001B[38;5;66;03m# We encode the training edge index to get the embeddings based on the training graph\u001B[39;00m\n\u001B[1;32m     81\u001B[0m \u001B[38;5;66;03m# structure and then use those embeddings to predict unseen edges\u001B[39;00m\n\u001B[1;32m     82\u001B[0m \u001B[38;5;66;03m# TODO: Check if this makes sense\u001B[39;00m\n\u001B[0;32m---> 83\u001B[0m pos_edge_rank, neg_edge_rank \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mx_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     84\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43medge_index_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_edge_index_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     85\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43medge_label_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43medge_label_index\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mchunk(\u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m     87\u001B[0m \u001B[38;5;66;03m# Calculate BPR loss\u001B[39;00m\n\u001B[1;32m     88\u001B[0m loss \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mrecommendation_loss(x_dict\u001B[38;5;241m=\u001B[39mdata\u001B[38;5;241m.\u001B[39mx_dict,\n\u001B[1;32m     89\u001B[0m                                  edge_index_dict\u001B[38;5;241m=\u001B[39mdata\u001B[38;5;241m.\u001B[39mtrain_edge_index_dict,\n\u001B[1;32m     90\u001B[0m                                  pos_edge_rank\u001B[38;5;241m=\u001B[39mpos_edge_rank,\n\u001B[1;32m     91\u001B[0m                                  neg_edge_rank\u001B[38;5;241m=\u001B[39mneg_edge_rank,\n\u001B[1;32m     92\u001B[0m                                  node_id\u001B[38;5;241m=\u001B[39medge_label_index\u001B[38;5;241m.\u001B[39munique())\n",
      "File \u001B[0;32m~/eutopia-colllaboration/ecr-recommender/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/eutopia-colllaboration/ecr-recommender/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[51], line 140\u001B[0m, in \u001B[0;36mCollaborationRecommender.forward\u001B[0;34m(self, x_dict, edge_index_dict, edge_label_index)\u001B[0m\n\u001B[1;32m    134\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    135\u001B[0m             x_dict,\n\u001B[1;32m    136\u001B[0m             edge_index_dict,\n\u001B[1;32m    137\u001B[0m             edge_label_index: OptTensor \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    138\u001B[0m \n\u001B[1;32m    139\u001B[0m     \u001B[38;5;66;03m# Encode authors\u001B[39;00m\n\u001B[0;32m--> 140\u001B[0m     z_dict \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_dict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index_dict\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    141\u001B[0m     z \u001B[38;5;241m=\u001B[39m z_dict[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mauthor\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m    142\u001B[0m     \u001B[38;5;66;03m# Decode edges\u001B[39;00m\n",
      "File \u001B[0;32m~/eutopia-colllaboration/ecr-recommender/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/eutopia-colllaboration/ecr-recommender/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[51], line 87\u001B[0m, in \u001B[0;36mEncoder.forward\u001B[0;34m(self, x_dict, edge_index_dict)\u001B[0m\n\u001B[1;32m     83\u001B[0m h_dict \u001B[38;5;241m=\u001B[39m x_dict\n\u001B[1;32m     85\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_layers):\n\u001B[1;32m     86\u001B[0m     \u001B[38;5;66;03m# Apply HANConv\u001B[39;00m\n\u001B[0;32m---> 87\u001B[0m     new_h_dict \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv_layers\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[43mh_dict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index_dict\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     89\u001B[0m     \u001B[38;5;66;03m# Add skip connection\u001B[39;00m\n\u001B[1;32m     90\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m ntype \u001B[38;5;129;01min\u001B[39;00m new_h_dict:\n",
      "File \u001B[0;32m~/eutopia-colllaboration/ecr-recommender/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1551\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/eutopia-colllaboration/ecr-recommender/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1557\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1558\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1560\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1561\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1562\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1564\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1565\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/eutopia-colllaboration/ecr-recommender/.venv/lib/python3.12/site-packages/torch_geometric/nn/conv/hgt_conv.py:199\u001B[0m, in \u001B[0;36mHGTConv.forward\u001B[0;34m(self, x_dict, edge_index_dict)\u001B[0m\n\u001B[1;32m    192\u001B[0m k, v, src_offset \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_construct_src_node_feat(\n\u001B[1;32m    193\u001B[0m     k_dict, v_dict, edge_index_dict)\n\u001B[1;32m    195\u001B[0m edge_index, edge_attr \u001B[38;5;241m=\u001B[39m construct_bipartite_edge_index(\n\u001B[1;32m    196\u001B[0m     edge_index_dict, src_offset, dst_offset, edge_attr_dict\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mp_rel,\n\u001B[1;32m    197\u001B[0m     num_nodes\u001B[38;5;241m=\u001B[39mk\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m))\n\u001B[0;32m--> 199\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpropagate\u001B[49m\u001B[43m(\u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mq\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_attr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43medge_attr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    201\u001B[0m \u001B[38;5;66;03m# Reconstruct output node embeddings dict:\u001B[39;00m\n\u001B[1;32m    202\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m node_type, start_offset \u001B[38;5;129;01min\u001B[39;00m dst_offset\u001B[38;5;241m.\u001B[39mitems():\n",
      "File \u001B[0;32m/tmp/torch_geometric.nn.conv.hgt_conv_HGTConv_propagate_4agopw5a.py:288\u001B[0m, in \u001B[0;36mpropagate\u001B[0;34m(self, edge_index, k, q, v, edge_attr, size)\u001B[0m\n\u001B[1;32m    276\u001B[0m             kwargs \u001B[38;5;241m=\u001B[39m CollectArgs(\n\u001B[1;32m    277\u001B[0m                 k_j\u001B[38;5;241m=\u001B[39mkwargs\u001B[38;5;241m.\u001B[39mk_j,\n\u001B[1;32m    278\u001B[0m                 q_i\u001B[38;5;241m=\u001B[39mkwargs\u001B[38;5;241m.\u001B[39mq_i,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    284\u001B[0m                 dim_size\u001B[38;5;241m=\u001B[39mhook_kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdim_size\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m    285\u001B[0m             )\n\u001B[1;32m    286\u001B[0m \u001B[38;5;66;03m# End Aggregate Forward Pre Hook #######################################\u001B[39;00m\n\u001B[0;32m--> 288\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maggregate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    289\u001B[0m \u001B[43m    \u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    290\u001B[0m \u001B[43m    \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    291\u001B[0m \u001B[43m    \u001B[49m\u001B[43mptr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mptr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    292\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdim_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdim_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    293\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    295\u001B[0m \u001B[38;5;66;03m# Begin Aggregate Forward Hook #########################################\u001B[39;00m\n\u001B[1;32m    296\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39mis_scripting() \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_compiling():\n",
      "File \u001B[0;32m~/eutopia-colllaboration/ecr-recommender/.venv/lib/python3.12/site-packages/torch_geometric/nn/conv/message_passing.py:577\u001B[0m, in \u001B[0;36mMessagePassing.aggregate\u001B[0;34m(self, inputs, index, ptr, dim_size)\u001B[0m\n\u001B[1;32m    566\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Constructs messages from node :math:`j` to node :math:`i`\u001B[39;00m\n\u001B[1;32m    567\u001B[0m \u001B[38;5;124;03m    in analogy to :math:`\\phi_{\\mathbf{\\Theta}}` for each edge in\u001B[39;00m\n\u001B[1;32m    568\u001B[0m \u001B[38;5;124;03m    :obj:`edge_index`.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    573\u001B[0m \u001B[38;5;124;03m    :obj:`_j` to the variable name, *.e.g.* :obj:`x_i` and :obj:`x_j`.\u001B[39;00m\n\u001B[1;32m    574\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m    575\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x_j\n\u001B[0;32m--> 577\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21maggregate\u001B[39m(\n\u001B[1;32m    578\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    579\u001B[0m     inputs: Tensor,\n\u001B[1;32m    580\u001B[0m     index: Tensor,\n\u001B[1;32m    581\u001B[0m     ptr: Optional[Tensor] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    582\u001B[0m     dim_size: Optional[\u001B[38;5;28mint\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    583\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m    584\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Aggregates messages from neighbors as\u001B[39;00m\n\u001B[1;32m    585\u001B[0m \u001B[38;5;124;03m    :math:`\\bigoplus_{j \\in \\mathcal{N}(i)}`.\u001B[39;00m\n\u001B[1;32m    586\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    592\u001B[0m \u001B[38;5;124;03m    as specified in :meth:`__init__` by the :obj:`aggr` argument.\u001B[39;00m\n\u001B[1;32m    593\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m    594\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maggr_module(inputs, index, ptr\u001B[38;5;241m=\u001B[39mptr, dim_size\u001B[38;5;241m=\u001B[39mdim_size,\n\u001B[1;32m    595\u001B[0m                             dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnode_dim)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for epoch in range(1,  100 + 1):\n",
    "    train_loss = train()\n",
    "    test_loss = test()\n",
    "    scheduler.step(test_loss)\n",
    "    eval_result = evaluate(k=num_recommendations)\n",
    "\n",
    "    # Save results\n",
    "    epoch_result = {\n",
    "        'epoch': epoch  ,\n",
    "        'train_loss_bpr': train_loss,\n",
    "        'test_loss_bpr': test_loss,\n",
    "        'precision@k': eval_result['precision@k'].compute(),\n",
    "        'recall@k': eval_result['recall@k'].compute(),\n",
    "        'map@k': eval_result['map@k'].compute(),\n",
    "        'mrr@k': eval_result['mrr@k'].compute(),\n",
    "        'ndcg@k': eval_result['ndcg@k'].compute(),\n",
    "        'hit_rate@k': eval_result['hit_rate@k'].compute()\n",
    "    }\n",
    "    results.append(epoch_result)\n",
    "\n",
    "    # Log results\n",
    "    if epoch % 1 == 0:\n",
    "        # Log model performance\n",
    "        formatted_str = ', '.join([f'{key}: {epoch_result[key]:.4f}' for key in epoch_result.keys()])\n",
    "        print(formatted_str)\n",
    "\n",
    "\n",
    "results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uV1aqHuN8Ixi",
   "metadata": {
    "id": "uV1aqHuN8Ixi"
   },
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eff30c4a-e7bb-45b4-99d9-59501ab656eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "MxwYhlsGRcG5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "MxwYhlsGRcG5",
    "outputId": "45bcc585-a9b1-4b1d-dbe1-e2c4b1fe2e50"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAABIGUlEQVR4nO3deXxU9b3/8ffMJJnsC0sWIOzITlAUiCKioIjWglJFagW9Vi8KXq1dflKroq2N1draVgv6sIJd3LAFrAuCKFAkiGzKIlQUSJQkrNmTSTJzfn+cySQDSVhM5iQnr+ej53HOnPnOzGcOx8473/M95zgMwzAEAABgE06rCwAAAGhOhBsAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGArhBsATVq0aJEcDoc2bdpkdSmnZdu2bfrBD36g9PR0ud1udejQQRMmTNDChQvl9XqtLg9ACIRZXQAANJcXXnhBs2bNUkpKim6++Wb169dPJSUlWrVqlW677Tbl5eXp5z//udVlAmhhhBsAtrBhwwbNmjVLmZmZeueddxQXFxd47t5779WmTZu0Y8eOZvmssrIyxcTENMt7AWh+HJYC0Cy2bt2qSZMmKT4+XrGxsRo/frw2bNgQ1Ka6ulqPPPKI+vXrp8jISHXs2FFjxozRypUrA23y8/N16623qlu3bnK73UpLS9PkyZO1f//+Jj//kUcekcPh0D/+8Y+gYFPr/PPP1y233CJJWr16tRwOh1avXh3UZv/+/XI4HFq0aFFg3S233KLY2Fh9+eWXuuqqqxQXF6ebbrpJc+bMUWxsrMrLy0/6rOnTpys1NTXoMNi7776riy++WDExMYqLi9PVV1+tnTt3NvmdAJwdwg2Ab23nzp26+OKL9emnn+pnP/uZHnzwQe3bt0/jxo3Txx9/HGg3b948PfLII7r00kv1zDPP6IEHHlD37t21ZcuWQJupU6dqyZIluvXWW/XnP/9Z//d//6eSkhLl5OQ0+vnl5eVatWqVxo4dq+7duzf796upqdHEiROVnJys3/72t5o6daqmTZumsrIyvf322yfV8u9//1vf+9735HK5JEl/+9vfdPXVVys2Nla/+c1v9OCDD2rXrl0aM2bMKUMbgLNgAEATFi5caEgyPvnkk0bbTJkyxYiIiDC+/PLLwLqDBw8acXFxxtixYwPrMjIyjKuvvrrR9zl+/LghyXjyySfPqMZPP/3UkGTcc889p9X+ww8/NCQZH374YdD6ffv2GZKMhQsXBtbNnDnTkGTcf//9QW19Pp/RtWtXY+rUqUHrX3/9dUOSsXbtWsMwDKOkpMRITEw0br/99qB2+fn5RkJCwknrAXx79NwA+Fa8Xq9WrFihKVOmqHfv3oH1aWlp+v73v69169apuLhYkpSYmKidO3fqiy++aPC9oqKiFBERodWrV+v48eOnXUPt+zd0OKq53HnnnUGPHQ6Hrr/+er3zzjsqLS0NrH/ttdfUtWtXjRkzRpK0cuVKFRYWavr06Tpy5EhgcrlcGjVqlD788MMWqxlorwg3AL6Vw4cPq7y8XP379z/puYEDB8rn8yk3N1eS9Oijj6qwsFDnnHOOhg4dqp/+9Kf67LPPAu3dbrd+85vf6N1331VKSorGjh2rJ554Qvn5+U3WEB8fL0kqKSlpxm9WJywsTN26dTtp/bRp01RRUaE333xTklRaWqp33nlH119/vRwOhyQFgtxll12mzp07B00rVqzQoUOHWqRmoD0j3AAImbFjx+rLL7/Uiy++qCFDhuiFF17QeeedpxdeeCHQ5t5779V///tfZWVlKTIyUg8++KAGDhyorVu3Nvq+ffv2VVhYmLZv335addQGjxM1dh0ct9stp/Pk/7scPXq0evbsqddff12S9O9//1sVFRWaNm1aoI3P55NkjrtZuXLlSdOyZctOq2YAp49wA+Bb6dy5s6Kjo7Vnz56Tntu9e7ecTqfS09MD6zp06KBbb71Vr7zyinJzczVs2DDNmzcv6HV9+vTRj3/8Y61YsUI7duxQVVWVnnrqqUZriI6O1mWXXaa1a9cGeomakpSUJEkqLCwMWn/gwIFTvvZEN9xwg5YvX67i4mK99tpr6tmzp0aPHh30XSQpOTlZEyZMOGkaN27cGX8mgKYRbgB8Ky6XS1dccYWWLVsWdOZPQUGBXn75ZY0ZMyZw2Ojo0aNBr42NjVXfvn3l8XgkmWcaVVZWBrXp06eP4uLiAm0a8/DDD8swDN18881BY2Bqbd68WS+99JIkqUePHnK5XFq7dm1Qmz//+c+n96XrmTZtmjwej1566SUtX75cN9xwQ9DzEydOVHx8vH7961+rurr6pNcfPnz4jD8TQNO4iB+A0/Liiy9q+fLlJ62/55579Ktf/UorV67UmDFjdNdddyksLEzPPfecPB6PnnjiiUDbQYMGady4cRoxYoQ6dOigTZs26Y033tCcOXMkSf/97381fvx43XDDDRo0aJDCwsK0ZMkSFRQU6MYbb2yyvgsvvFDPPvus7rrrLg0YMCDoCsWrV6/Wm2++qV/96leSpISEBF1//fX605/+JIfDoT59+uitt946q/Ev5513nvr27asHHnhAHo8n6JCUZI4Hmj9/vm6++Wadd955uvHGG9W5c2fl5OTo7bff1kUXXaRnnnnmjD8XQBOsPl0LQOtWeyp4Y1Nubq5hGIaxZcsWY+LEiUZsbKwRHR1tXHrppcb69euD3utXv/qVMXLkSCMxMdGIiooyBgwYYDz22GNGVVWVYRiGceTIEWP27NnGgAEDjJiYGCMhIcEYNWqU8frrr592vZs3bza+//3vG126dDHCw8ONpKQkY/z48cZLL71keL3eQLvDhw8bU6dONaKjo42kpCTjf//3f40dO3Y0eCp4TExMk5/5wAMPGJKMvn37Ntrmww8/NCZOnGgkJCQYkZGRRp8+fYxbbrnF2LRp02l/NwCnx2EYhmFZsgIAAGhmjLkBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC2QrgBAAC20u4u4ufz+XTw4EHFxcU1en8ZAADQuhiGoZKSEnXp0qXBe73V1+7CzcGDB4PucwMAANqO3NxcdevWrck27S7cxMXFSTI3Tu39bgAAQOtWXFys9PT0wO94U9pduKk9FBUfH0+4AQCgjTmdISUMKAYAALZCuAEAALZCuAEAALZCuAEAALZCuAEAALZCuAEAALZCuAEAALZCuAEAALZCuAEAALZCuAEAALZCuAEAALZCuAEAALZCuGlOZUekgp1WVwEAQLtGuGkuu9+WnuwjLZtjdSUAALRrhJvmkjbcnOdtkyoKLSwEAID2jXDTXBK6Sh37SoZPOrDe6moAAGi3CDfNqefF5nzfWmvrAACgHSPcNKdeY835/v9YWwcAAO0Y4aY51fbcFOwwz5wCAAAhR7hpTrGdpeTB5jK9NwAAWIJw09x6Me4GAAArEW6aW+24m3303AAAYAXCTXPrcZHkcEpHv5CKD1pdDQAA7Q7hprlFJUppGeYyvTcAAIQc4aYlBA5NMe4GAIBQI9y0hJ6117sh3AAAEGqEm5bQfbTkDJMKc6Tj+62uBgCAdoVw0xLcsVLX881lDk0BABBShJuWwrgbAAAsQbhpKfXDjWFYWwsAAO0I4aaldLtAcrml0gLpyBdWVwMAQLtBuGkp4ZFS91Hm8r411tYCAEA7Ymm4mT9/voYNG6b4+HjFx8crMzNT7777bqPtFy1aJIfDETRFRkaGsOIzxLgbAABCLszKD+/WrZsef/xx9evXT4Zh6KWXXtLkyZO1detWDR48uMHXxMfHa8+ePYHHDocjVOWeuV6XSPqVeYdwn09y0lEGAEBLszTcXHPNNUGPH3vsMc2fP18bNmxoNNw4HA6lpqaGorxvr8u5UniMVHFcOrRTSh1qdUUAANheq+lK8Hq9evXVV1VWVqbMzMxG25WWlqpHjx5KT0/X5MmTtXPnzibf1+PxqLi4OGgKGVe41ONCc5lDUwAAhITl4Wb79u2KjY2V2+3WrFmztGTJEg0aNKjBtv3799eLL76oZcuW6e9//7t8Pp8uvPBCff31142+f1ZWlhISEgJTenp6S32VhjHuBgCAkHIYhrUXYamqqlJOTo6Kior0xhtv6IUXXtCaNWsaDTj1VVdXa+DAgZo+fbp++ctfNtjG4/HI4/EEHhcXFys9PV1FRUWKj49vtu/RqIPbpOcvkSLipP+3X3JZeiQQAIA2qbi4WAkJCaf1+235L21ERIT69u0rSRoxYoQ++eQT/eEPf9Bzzz13yteGh4fr3HPP1d69extt43a75Xa7m63eM5Y6VIpMlCoLpbxPpW4jrKsFAIB2wPLDUify+XxBPS1N8Xq92r59u9LS0lq4qm/B6ZJ6jjGXud4NAAAtztJwM3fuXK1du1b79+/X9u3bNXfuXK1evVo33XSTJGnGjBmaO3duoP2jjz6qFStW6KuvvtKWLVv0gx/8QAcOHNAPf/hDq77C6WHcDQAAIWPpYalDhw5pxowZysvLU0JCgoYNG6b33ntPl19+uSQpJydHznrXhjl+/Lhuv/125efnKykpSSNGjND69etPa3yOpWrDTc4GqcYjhVl4mAwAAJuzfEBxqJ3JgKRmYxjSb/tJZYelW9+tOz0cAACcljP5/W51Y25syeHg0BQAACFCuAmVnhebc8INAAAtinATKrU9N7kbpapya2sBAMDGCDeh0qG3FN9N8lVLuR9bXQ0AALZFuAkVxt0AABAShJtQ6sW4GwAAWhrhJpRqBxUf3CJVFllbCwAANkW4CaXEdHPsjeGTDmRbXQ0AALZEuAm12nE3+/9jbR0AANgU4SbUAoOKuYkmAAAtgXATarXjbvK3S+XHrK0FAAAbItyEWmyy1HmgucyhKQAAmh3hxgqBQ1OEGwAAmhvhxgpczA8AgBZDuLFCz4skOaQje6SSfKurAQDAVgg3VohKktKGmcscmgIAoFkRbqwSuN4Nh6YAAGhOhBur9LrEnDPuBgCAZkW4sUr30ZIzTDq+Xzp+wOpqAACwDcKNVdxxUtcR5jLXuwEAoNkQbqxUe7ViBhUDANBsCDdWqn+9G8OwthYAAGyCcGOl9JGSyy2VHJRyP7a6GgAAbIFwY6XwKCljmrm89klrawEAwCYIN1Ybc5/kcEl735e+2Wx1NQAAtHmEG6t16CUNu8FcXvtba2sBAMAGCDetwcU/luSQ9rwj5X1mdTUAALRphJvWoFM/achUc5mxNwAAfCuEm9Zi7E/M+edvSoc+t7YWAADaMMJNa5E8UBr4XXOZsTcAAJw1wk1rMvan5nznv6QjX1hbCwAAbRThpjVJGyadM0kyfNJ/nrK6GgAA2iTCTWtzib/35rPXpWP7rK0FAIA2iHDT2nQdIfWdIBlead3vrK4GAIA2x9JwM3/+fA0bNkzx8fGKj49XZmam3n333SZfs3jxYg0YMECRkZEaOnSo3nnnnRBVG0Jjf2bOt70iFeZYWwsAAG2MpeGmW7duevzxx7V582Zt2rRJl112mSZPnqydO3c22H79+vWaPn26brvtNm3dulVTpkzRlClTtGPHjhBX3sK6jzLvGO6rltY9bXU1AAC0KQ7DMAyri6ivQ4cOevLJJ3Xbbbed9Ny0adNUVlamt956K7Bu9OjRGj58uBYsWHBa719cXKyEhAQVFRUpPj6+2epudvv+I730HckVId3zqRTfxeqKAACwzJn8freaMTder1evvvqqysrKlJmZ2WCb7OxsTZgwIWjdxIkTlZ2d3ej7ejweFRcXB01tQs8xUvcLJW+V9NEfra4GAIA2w/Jws337dsXGxsrtdmvWrFlasmSJBg0a1GDb/Px8paSkBK1LSUlRfn5+o++flZWlhISEwJSent6s9bcYh6PuzKnNC6XSQ9bWAwBAG2F5uOnfv7+2bdumjz/+WHfeeadmzpypXbt2Ndv7z507V0VFRYEpNze32d67xfW+VOp6vlRTKa3/k9XVAADQJlgebiIiItS3b1+NGDFCWVlZysjI0B/+8IcG26ampqqgoCBoXUFBgVJTUxt9f7fbHTgbq3ZqMxwO6RL/mVOf/EUqO2ptPQAAtAGWh5sT+Xw+eTyeBp/LzMzUqlWrgtatXLmy0TE6ttDvCiktQ6oukzY8a3U1AAC0epaGm7lz52rt2rXav3+/tm/frrlz52r16tW66aabJEkzZszQ3LlzA+3vueceLV++XE899ZR2796tefPmadOmTZozZ45VX6HlORx11735+Hmp4ri19QAA0MpZGm4OHTqkGTNmqH///ho/frw++eQTvffee7r88sslSTk5OcrLywu0v/DCC/Xyyy/r+eefV0ZGht544w0tXbpUQ4YMseorhEb/q6TkwVJVifTxc1ZXAwBAq9bqrnPT0trMdW5OtONf0hu3SpEJ0r07pMg2VDsAAN9Sm7zODU5h0GSp0zlSZZG08XmrqwEAoNUi3LQVTpc01n/dm+xnJU+ptfUAANBKEW7aksHXSR16SxXHpE0vWl0NAACtEuGmLXGFSRf/2Fxe/0epqtzaegAAaIUIN23NsGlSYnep7LD04WNWVwMAQKtDuGlrXOHSlY+by9nPSDuXWloOAACtDeGmLRpwtXTh/5nLy+ZIR76wth4AAFoRwk1bNf5hqcdF5oX9XrtZqiqzuiIAAFoFwk1b5QqTvrdQik2RDn8u/fseqX1djxEAgAYRbtqyuBTp+kWSwyVtXyx98oLVFQEAYDnCTVvX40Lp8kfN5eVzpdxPrK0HAACLEW7sIHO2NPC7kq9aWjxTKjtidUUAAFiGcGMHDoc0+VmpYz+p+Bvpn7dJPq/VVQEAYAnCjV1ExkvT/iaFR0tfrZZWZ1ldEQAAliDc2EnyQOmaP5rLa5+U/vuetfUAAGABwo3dDLteGnmHufyv26Xj+y0tBwCAUCPc2NEVj0ldz5cqi8wL/FVXWl0RAAAhQ7ixo7AI6YaXpOiOUv5n0rs/tboiAABChnBjVwndpKl/keSQtvxV2vI3qysCACAkCDd21udS6bIHzOV3fiLlfWptPQAAhADhxu7G/FjqN1GqqTTH31Qct7oiAABaFOHG7pxO6brnpMTuUuEB6S8TpW82W10VAAAthnDTHkQlSTe+bN5B/Mge6YXLpQ8ek2qqrK4MAIBmR7hpL1KHSndtkIZMlQyvtPYJ6YXLpIKdVlcGAECzIty0J9EdpO+9KF2/SIrqIOVvl567RPrPU5K3xurqAABoFoSb9mjwtdLsj6X+V5l3El/1qPTiROnIF1ZXBgDAt0a4aa9ik81xOFMWSO4E6ZtN0oIx0ob5ks9ndXUAAJw1wk175nBIw6dLd62Xel9qni6+/H7ppWu4JxUAoM0i3MC8mvHNS6Tv/F4Kj5EOrJP+fKG0aaFkGFZXBwDAGSHcwORwSOf/j3TnR1L3C6XqMumte6W/T5WKvra6OgAAThvhBsE69JJueVua+GspLFL6cpX0h+HSP2+XvubifwCA1o9wg5M5nVLmbOl//yP1GGOeUbX9dfO6OC9MkLa/IXmrra4SAIAGOQyjfQ2qKC4uVkJCgoqKihQfH291OW3DN1ukj5+TdvzTDDqSFJcmXXCbNOJWKaaTtfUBAGzvTH6/CTc4fSUF0uaF0id/kcoOmetcbmno9dKo/5XShllbHwDAts7k99vSw1JZWVm64IILFBcXp+TkZE2ZMkV79uxp8jWLFi2Sw+EImiIjI0NUcTsXlyKNu1/60Q7p2uelLudKXo+07e/ScxdLC6+Sdr3J1Y4BAJYKs/LD16xZo9mzZ+uCCy5QTU2Nfv7zn+uKK67Qrl27FBMT0+jr4uPjg0KQw+EIRbmoFeaWMqZJw26Qvv7EvPDfrmXSgY/MKaG7NGKG1PdyKXWYOYYHAIAQaVWHpQ4fPqzk5GStWbNGY8eObbDNokWLdO+996qwsPCsPoPDUi2k6Btp01/Ma+NUHKtbH9VB6nWx1HucOSX1Mk87BwDgDJzJ77elPTcnKioqkiR16NChyXalpaXq0aOHfD6fzjvvPP3617/W4MGDG2zr8Xjk8XgCj4uLi5uvYNRJ6CqNf0ga+1Nz4PHnb0n715lBZ9cyc5KkxO5myOl1iTnFdra0bACA/bSanhufz6fvfve7Kiws1Lp16xptl52drS+++ELDhg1TUVGRfvvb32rt2rXauXOnunXrdlL7efPm6ZFHHjlpPT03IeCtlg5ulb5abU65G+vOtqqVMlTqfYkZeLpnSu5YCwoFALR2bfJsqTvvvFPvvvuu1q1b12BIaUx1dbUGDhyo6dOn65e//OVJzzfUc5Oenk64sYKnVMrJ9oedNVLB9uDnnWFS6lCp20gp3T8lpHMYCwDQ9g5LzZkzR2+99ZbWrl17RsFGksLDw3Xuuedq7969DT7vdrvldrubo0x8W+5Yqd/l5iRJpYelfWvqenaKcs2enoNbpY3PmW1iU6X0C6T0UWboScuQwjk7DgDQOEvDjWEYuvvuu7VkyRKtXr1avXr1OuP38Hq92r59u6666qoWqBAtKrazNPR75mQYUmGOefZV7kYp92Mpf7tUmi99/m9zkiRXhHkGVm3PTreR5ngfAAD8LD0sddddd+nll1/WsmXL1L9//8D6hIQERUVFSZJmzJihrl27KisrS5L06KOPavTo0erbt68KCwv15JNPaunSpdq8ebMGDRp0ys/kbKk2pKrc7MX5eqOU+4k5Lzt8crtO/aX+k6QBV0tdR0hOV+hrBQC0qDZzWGr+/PmSpHHjxgWtX7hwoW655RZJUk5Ojpz1rpNy/Phx3X777crPz1dSUpJGjBih9evXn1awQRsTES31vMicJLN35/i+uqCTu1Eq2Ckd2WNOHz0txXSWzrlS6n+VOUg5ItrKbwAAsECrGVAcKvTc2ExlkfTFSmnPu+bcU1T3XFiU1OdSM+iccyWnnQNAG9Ymz5YKFcKNjdVUSTnrpd3vSHveMQcoBzjMMTr9J0n9r5Y6n2NZmQCAM0e4aQLhpp0wDKlgh9mjs/ttKW9b8PNxXaTUIVLKEPP089ShUofejNcBgFaKcNMEwk07VfSN9N93zbCzb63krTq5TXi0lDyoXugZJqUMktxxoa8XABCEcNMEwg3kKTUHIud/Zvbu5G+XCnZJNRUNt0/qZQae5EHm7SMS0s15fFcpLCK0tQNAO0W4aQLhBg3yeaVjX5mBJ7828OyQSvKaeJFDikuTEtP9gccfehK6163jbC0AaBaEmyYQbnBGyo7UBZ0j/5UKc82ByoW5ktdz6tdHJUmRCVJEnHmFZnecFBFrLkfEmY/dsf51cXXzDr2luFRuPQEAfm3mOjdAqxfTyTydvM+lwesNw7ygYGGOOdUGnvpzT7FUcdyczkZ0x+ABzylDpE7ncCgMAE6BnhugpVQUSsUHJU+JVFVijvXxlEhVpeZyVYn52FPqX+d/XFkkFR6QDN/J7+kMlzoP8Aeeemd7RXcI+dcDgFCi5wZoDaISzelsVFdIhz6vOySWv8Oce4rNu6kXbJc+rdc+rovUub+U1ENK7FE3T+xh9j61tcNbhmEGPVe4FB5ldTUA2hjCDdAahUdJXc8zp1q1NxcNBB7//Ph+qeSgOTX4XjHmQOfE7ieEH/8ZXxExUlhk8wYgn7deD5V/XlloThWFZu9UU8uVRf6eK4c5MLtjH6ljX3Pq5J8npHNdIgAN4rAU0NZVFkuHdklH95rh5/gB87DW8QP+s71O5z9xh3mdn/Ao8wyvcP8UEWOuCzyOllxuqbq83qG00rrDbrXrqstb+lubdXToXRd8OvWrC0DRHdtebxWAJnG2VBMIN2hXajxS0ddm705t4CnMqVsuP9Kyn+8MqzsDLDLBPyWah+siE83HDS1H+R9XlZmh7ehe6cgX/uUvpWNfNnwhxloRcVKHnmb4Seoldejln/eW4rvQ4wO0QYSbJhBugHq8NebFC6vKzd6W6nJzvE9VmTmv9s/rP19TaR7qCpzCHlt3qnvtY3e8uRzmbpkeFJ/XPCPt6F7pyN66AHR07wn3FGuAK8I8NFc/8HTobV6NOr4rPT5AK0W4aQLhBrC56kqzZ+rYV9KxfdLxfeb82Fdmr5WvuvHXRiX5z0Qb5p+Gmoe7XOGhqx9AgzhbCkD7FR5pnjnWuf/Jz/m8/sN0+4LDz9EvpcN7zGsS7VtrTrVcbil5YF3oSRsmpQzmnmNAK0a4AdB+OF3mmWJJPaTe44Kfq66UDu82z0LL/8w/32EOls7bdvKd5Tv0Nq8zlDK4bkrsKTmdofkuABrFYSkAaIzPJxXuN4NOXm3g2d70affJA83xO7XBJ3kQF1kEmgFjbppAuAHwrZUd8d9Vfpd5h/lDO6VDuxu/31hcF3/gGSylDJXSMsxT2DlrCzhthJsmEG4AtAhvjTmOp2CHP/DsMpcLcxpuHx5jjuNJy5C6DDfnnfpLLkYLAA0h3DSBcAMgpCqLzVtpHNpphp7aQ1sNXegwLNLs3UnL8E/DzcNcYe6Qlw20NpwtBQCtRWS81H2UOdXyec1r8hzcJuV9ak75n5n3DvtmsznVcoabh7S6Xyj1HCP1uJAxPMAp0HMDAK2Bz2eell4bdvI+Nc/Qqjh+ctvkwWbQ6XmR1OMi8+aogM1xWKoJhBsAbYZhmNfl+foT6cBH0v515unqJ+o80Aw6PceYYSc2OfS1Ai2McNMEwg2ANq30sBl0asPOoV0nt+l0jhlyuo+Wup5vnpnFbSXQxhFumkC4AWArZUelnPVm0Nn/kXmG1ol3go9MlLqdbwadbudLXUcwbgdtDuGmCYQbALZWfkzKyZYOrJe+3mSO26mpPLldhz7BgSdliBQWEfJy0coZhuStMveh6kpzXuOpN6844bG/TXQnafCUZi2FcNMEwg2AdsVbbfbmfL3JnL7ZZJ6pdSKX2zz9PGWQlNSzbkrsYd5QlMNa9lVVLh3fb16nqf591459ZY75Mrxn/p7po6TbVjRrmZwKDgAwucKlLuea08jbzXXlx6RvtphBpzbwVByXvt5oTidyJ/jvydWz3ryneS+txHSuw9PaeWukimNS8cGGA0xJ3um/V1iU+e8dFmnOw094HBZpTp3OabnvcxrouQGA9s4wzB+5r/29OoUHzL/kj++XSgtO8WKHeXZWdEdzikoyx/NEd5Si/PPA4yRzHplAT9C34fNKlUVS2WHzViBlh82p/Gjdclm95YrjOmkc1okiE8ybwXboLSX1qltO7C65Y83A4oqw9N+NnhsAwOlzOMwzqjr2Ofm5qnLzFhK1Yef4/uDwU11uBqBThqD6n+cyg447VoqonWJO73FYpHkIzRVu9hS4IvxztzlmyOVfF4q7sxuGOc6kulyqKpOqK8zxJt4qc73XI9VUnTCvPHlddaX5HjX+eXVF8FRTu1xutm3sHmZNckgxnaUOvRoIMb1sN8CccAMAaFxEtJQ8wJxOZBhmz0DxQfOwR7l/Ciwf9S8flcqPm8tVpeYYjvIj5tRSnGEnB56wCHPuCvfP3fWW64UlV7j5HlXl9YJLuf9xmX9eYS4bvpb7DqcSmWhewDGms9kjFtPZP3Wqt7523qFd3aiVcAMAODsO/yGpM7loYI3HH4COm0GnqlTylJoB4qTHJea8/uOTekL8c29V8Of4asypuqx5v3NjXPXGn9QPVSfN6/c2RdSNWwmP9r8+yv+4dl1k3XP127jjOLutCYQbAEDohLml+DRzak6BU5Y9DRwWOnGqrluuaWS9DPPO7eFR5iGx8GizFys8xj+PrlsfHs3d3FsZ/jUAAG2fw+E/W4cztyCFYMRV47KysnTBBRcoLi5OycnJmjJlivbs2XPK1y1evFgDBgxQZGSkhg4dqnfeeScE1QIAgLbA0nCzZs0azZ49Wxs2bNDKlStVXV2tK664QmVljR8jXb9+vaZPn67bbrtNW7du1ZQpUzRlyhTt2LEjhJUDAIDWqlVd5+bw4cNKTk7WmjVrNHbs2AbbTJs2TWVlZXrrrbcC60aPHq3hw4drwYIFp/wMrnMDAEDbcya/32fVc5Obm6uvv/468Hjjxo2699579fzzz5/N2wUUFRVJkjp0aPx8++zsbE2YMCFo3cSJE5Wdnd1ge4/Ho+Li4qAJAADY11mFm+9///v68MMPJUn5+fm6/PLLtXHjRj3wwAN69NFHz6oQn8+ne++9VxdddJGGDBnSaLv8/HylpKQErUtJSVF+fn6D7bOyspSQkBCY0tPTz6o+AADQNpxVuNmxY4dGjhwpSXr99dc1ZMgQrV+/Xv/4xz+0aNGisypk9uzZ2rFjh1599dWzen1j5s6dq6KiosCUm5vbrO8PAABal7M6Fby6ulput3m63fvvv6/vfve7kqQBAwYoL+8MbsDlN2fOHL311ltau3atunXr1mTb1NRUFRQEX+a7oKBAqampDbZ3u92BWgEAgP2dVc/N4MGDtWDBAv3nP//RypUrdeWVV0qSDh48qI4dO572+xiGoTlz5mjJkiX64IMP1KtXr1O+JjMzU6tWrQpat3LlSmVmZp7ZlwAAALZ0VuHmN7/5jZ577jmNGzdO06dPV0ZGhiTpzTffDByuOh2zZ8/W3//+d7388suKi4tTfn6+8vPzVVFREWgzY8YMzZ07N/D4nnvu0fLly/XUU09p9+7dmjdvnjZt2qQ5c+aczVcBAAA2c9angnu9XhUXFyspKSmwbv/+/YqOjlZy8undZ8TRyK3TFy5cqFtuuUWSNG7cOPXs2TNoLM/ixYv1i1/8Qvv371e/fv30xBNP6Kqrrjqtz+RUcAAA2p4z+f0+q3BTUVEhwzAUHR0tSTpw4ICWLFmigQMHauLEiWdXdYgQbgAAaHta/Do3kydP1l//+ldJUmFhoUaNGqWnnnpKU6ZM0fz588/mLQEAAJrFWYWbLVu26OKLL5YkvfHGG0pJSdGBAwf017/+VX/84x+btUAAAIAzcVbhpry8XHFxcZKkFStW6LrrrpPT6dTo0aN14MCBZi0QAADgTJxVuOnbt6+WLl2q3Nxcvffee7riiiskSYcOHWIcCwAAsNRZhZuHHnpIP/nJT9SzZ0+NHDkycI2ZFStW6Nxzz23WAgEAAM7EWZ8Knp+fr7y8PGVkZMjpNDPSxo0bFR8frwEDBjRrkc2Js6UAAGh7zuT3+6xuvyCZt0FITU0N3B28W7duZ3QBPwAAgJZwVoelfD6fHn30USUkJKhHjx7q0aOHEhMT9ctf/lI+n6+5awQAADhtZ9Vz88ADD+gvf/mLHn/8cV100UWSpHXr1mnevHmqrKzUY4891qxFAgAAnK6zGnPTpUsXLViwIHA38FrLli3TXXfdpW+++abZCmxujLkBAKDtafErFB87dqzBQcMDBgzQsWPHzuYtAQAAmsVZhZuMjAw988wzJ61/5plnNGzYsG9dFAAAwNk6qzE3TzzxhK6++mq9//77gWvcZGdnKzc3V++8806zFggAAHAmzqrn5pJLLtF///tfXXvttSosLFRhYaGuu+467dy5U3/729+au0YAAIDTdtYX8WvIp59+qvPOO09er7e53rLZMaAYAIC2p8UHFAMAALRWhBsAAGArhBsAAGArZ3S21HXXXdfk84WFhd+mFgAAgG/tjMJNQkLCKZ+fMWPGtyoIAADg2zijcLNw4cKWqgMAAKBZMOYGAADYCuEGAADYCuEGAADYCuEGAADYCuEGAADYCuEGAADYCuEGAADYCuEGAADYCuEGAADYCuEGAADYCuEGAADYCuEGAADYCuEGAADYiqXhZu3atbrmmmvUpUsXORwOLV26tMn2q1evlsPhOGnKz88PTcEAAKDVszTclJWVKSMjQ88+++wZvW7Pnj3Ky8sLTMnJyS1UIQAAaGvCrPzwSZMmadKkSWf8uuTkZCUmJjZ/QQAAoM1rk2Nuhg8frrS0NF1++eX66KOPmmzr8XhUXFwcNAEAAPtqU+EmLS1NCxYs0D//+U/985//VHp6usaNG6ctW7Y0+pqsrCwlJCQEpvT09BBWDAAAQs1hGIZhdRGS5HA4tGTJEk2ZMuWMXnfJJZeoe/fu+tvf/tbg8x6PRx6PJ/C4uLhY6enpKioqUnx8/LcpGQAAhEhxcbESEhJO6/fb0jE3zWHkyJFat25do8+73W653e4QVgQAAKzUpg5LNWTbtm1KS0uzugwAANBKWNpzU1paqr179wYe79u3T9u2bVOHDh3UvXt3zZ07V998843++te/SpKefvpp9erVS4MHD1ZlZaVeeOEFffDBB1qxYoVVXwEAALQyloabTZs26dJLLw08vu+++yRJM2fO1KJFi5SXl6ecnJzA81VVVfrxj3+sb775RtHR0Ro2bJjef//9oPcAAADtW6sZUBwqZzIgCQAAtA5n8vvd5sfcAAAA1Ee4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtkK4AQAAtmJpuFm7dq2uueYadenSRQ6HQ0uXLj3la1avXq3zzjtPbrdbffv21aJFi1q8TgAA0HZYGm7KysqUkZGhZ5999rTa79u3T1dffbUuvfRSbdu2Tffee69++MMf6r333mvhSgEAQFsRZuWHT5o0SZMmTTrt9gsWLFCvXr301FNPSZIGDhyodevW6fe//70mTpzYUmUCAIA2pE2NucnOztaECROC1k2cOFHZ2dmNvsbj8ai4uDhoAgAA9tWmwk1+fr5SUlKC1qWkpKi4uFgVFRUNviYrK0sJCQmBKT09PRSlAgAAi7SpcHM25s6dq6KiosCUm5trdUkAAKAFWTrm5kylpqaqoKAgaF1BQYHi4+MVFRXV4GvcbrfcbncoygMAAK1Am+q5yczM1KpVq4LWrVy5UpmZmRZVBAAAWhtLw01paam2bdumbdu2STJP9d62bZtycnIkmYeUZsyYEWg/a9YsffXVV/rZz36m3bt3689//rNef/11/ehHP7KifAAA0ApZGm42bdqkc889V+eee64k6b777tO5556rhx56SJKUl5cXCDqS1KtXL7399ttauXKlMjIy9NRTT+mFF17gNHAAABDgMAzDsLqIUCouLlZCQoKKiooUHx9vdTkAAOA0nMnvd5sacwMAAHAqhBsAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGArrSLcPPvss+rZs6ciIyM1atQobdy4sdG2ixYtksPhCJoiIyNDWC0AAGjNLA83r732mu677z49/PDD2rJlizIyMjRx4kQdOnSo0dfEx8crLy8vMB04cCCEFQMAgNbM8nDzu9/9TrfffrtuvfVWDRo0SAsWLFB0dLRefPHFRl/jcDiUmpoamFJSUkJYMQAAaM0sDTdVVVXavHmzJkyYEFjndDo1YcIEZWdnN/q60tJS9ejRQ+np6Zo8ebJ27tzZaFuPx6Pi4uKgCQAA2Jel4ebIkSPyer0n9bykpKQoPz+/wdf0799fL774opYtW6a///3v8vl8uvDCC/X111832D4rK0sJCQmBKT09vdm/BwAAaD0sPyx1pjIzMzVjxgwNHz5cl1xyif71r3+pc+fOeu655xpsP3fuXBUVFQWm3NzcEFcMAABCKczKD+/UqZNcLpcKCgqC1hcUFCg1NfW03iM8PFznnnuu9u7d2+Dzbrdbbrf7W9cKAADaBkt7biIiIjRixAitWrUqsM7n82nVqlXKzMw8rffwer3avn270tLSWqpMAADQhljacyNJ9913n2bOnKnzzz9fI0eO1NNPP62ysjLdeuutkqQZM2aoa9euysrKkiQ9+uijGj16tPr27avCwkI9+eSTOnDggH74wx9a+TUAAEArYXm4mTZtmg4fPqyHHnpI+fn5Gj58uJYvXx4YZJyTkyOns66D6fjx47r99tuVn5+vpKQkjRgxQuvXr9egQYOs+goAAKAVcRiGYVhdRCgVFxcrISFBRUVFio+Pt7ocAABwGs7k97vNnS0FAADQFMINAACwFcINAACwFcINAACwFcINAACwFcINAACwFcINAACwFcINAACwFcINAACwFcINAACwFcINAACwFcJNM9p1sFiV1V6rywAAoF0j3DSTnQeLNO25bM14caOKK6utLgcAgHaLcNNMSitrZEjauO+Ybnxugw6XeKwuCQCAdolw00xG9e6oV+8YrU6xEdqVV6zrF6xX7rFyq8sCAKDdIdw0oyFdE7R41oXqlhSl/UfLNXX+eu3OL7a6LAAA2hXCTTPr1SlG/7zzQvVPidOhEo9uWJCtTfuPWV0WAADtBuGmBaTER+r1/83UiB5JKq6s0Q/+8rE+2F1gdVkAALQLhJsWkhAdrr/fNkqX9u+symqfbv/rZi3Z+rXVZQEAYHuEmxYUFeHS8zPO17XndpXXZ+hHr32qF9fts7osAABsjXDTwsJdTj11fYZuvainJOnRt3bpt+/tkWEY1hYGAIBNEW5CwOl06KHvDNJPrjhHkvTMh3v1wNId8voIOAAANDfCTYg4HA7NuayfHrt2iBwO6eWPc3T3K1vkqeF2DQAANCfCTYjdNKqHnpl+nsJdDr2zPV//s+gTlXpqrC4LAADbINxY4OphaVp4y0hFR7j00d6jmvLsR3puzZfad6TM6tIAAGjzHEY7G9laXFyshIQEFRUVKT4+3tJaPs0t1K2LPtGxsqrAun7JsbpicIquGJSqYd0S5HA4LKwQAIDW4Ux+vwk3Fjta6tE72/O0YleBsr88qpp6g4xT4yMDQWdU7w4Kd9HRBgBonwg3TWht4aa+oopqrd5zSCt2Fmj1nkMqq6obbBwXGabxA5J1xeBUXXJOZ8W4wyysFACA0CLcNKE1h5v6Kqu9yv7yqFbsytfKXQU6Ulp36CoizKlRvTqoe4dopSVEKiU+UqkJkUqNj1RKQqTi3GEczgIA2ArhpgltJdzU5/UZ2ppzXCt2Fei9nfk6cLS8yfbRES4z6PhDT0p8pFLj3UqOj5RhmMGpssYrT7VPlTVeVVb75Kn2ylPjM5+rt+yp8Sk6IkxdEiOVlhClLolmiOqSGKWU+EhFhHGoDADQ8gg3TWiL4aY+wzD0xaFSbdx3TAXFlcovqlR+cWVgubgydKeVOxxSp1i3uiSYwSctMVJd/PPU+Eglx0UqOd6tyHBXyGoCANjTmfx+M3CjjXE4HDonJU7npMQ1+Hx5VY0Kij3KL/IHHn/oKSiu1OESj5xOh9xhTkWGuxQZ7vIvOxUZVv+xS5HhTrn9j4sra5RXWKG8okodLKxQfnGl8ooqVVXj0+ESjw6XePTp10WN1hznDlPneLeS49zqHBfpn7vrzc11idHhHE4DAHxrhBubiY4IU69OYerVKaZFP8cwDB0tq1JeYaUOFlUov8ic5xVWKq/IDECHij3y1PhU4qlRyeEafXW46ev4uJwORYe7FBnhUpQ/YEX5Q1iUf11Uvedr29QGotpOyNq+SCNoOfg5p8Mhl1NyOZ0KczrkcjoU5vLPnQ45HbWP6z0fmDsV5mr8cbjLGdTekOQzDBmGOfcZks9/VlzgsWHICLSRwlwORbiccoc5FVE7uZwK44w5ADglwg3OisPhUKdYtzrFujW0W0KDbQzDUImnRodLPDpU7NGhkspAT8/hEo8OBeaVOl5eLa/PbF/CFZsb5XKaoad+4KkNQFERLsVFhivOHaZYd5hiI8MUF2kum/Nwcx4Zpjh3mOIiwxUV7pKhuuBVGwgNGfL/74TnzFAWEeaU2+WSO9yswelsXz1uhmGo2muYQbidfXegLWgV4ebZZ5/Vk08+qfz8fGVkZOhPf/qTRo4c2Wj7xYsX68EHH9T+/fvVr18//eY3v9FVV10VwopxOhwOh+IjwxUfGa4+nWObbFtV49Px8ipVVHlVUW1OlfWWK6rMgc7mss983r++tlfGIYdqj2rVHd2qt051z/kMyes15DUMeX2GanyGvD6fvL76jw3V1G/j9clrmOtqn6/2+oLa139c4/XJF+gpMnuLnA6zHscJj4Pmkqq9PlV5faqqqXsPyRxcXuEzt0NrEl7b0+Q/lBkR5qw3d/l7nWp7s/y9YUG9Xw30krnMf7Eab/C2rfYaqvH5Ats4aJ3XkM+o2x/8/wva7sH7ibm9HQ5zm1fXGKry+sztX2POq71G4N+i2lu3Tv7XxUaE1YXGyPBAsIwPBMvgdRFhTnl9CuxrXsOQ78TloHXy75tmyKx9XWA50NZ8vqa2ra+ubk+NT54ab2C5qsbcv05aV+OTIXN/dTgccjokV/391N+rWX9/djqk8DCnYiLM7xjrD9cx7jDFul2KdYcrxu1SXGTtOnOKjggLhONQ9VD6/H9AFZZXqbC8WsfLq1RUUa3jZVUqrKhWYXm1CsurAn9sdYyNUOdYtzrFuQPzTrER6hznVscYt1wE21bL8nDz2muv6b777tOCBQs0atQoPf3005o4caL27Nmj5OTkk9qvX79e06dPV1ZWlr7zne/o5Zdf1pQpU7RlyxYNGTLEgm+A5hAR5lRKfKTVZTQ7wzC+9TiiGn/Q8VT7gn6sAj9Q1V5VeX0qr/KqtLJGJZXVKvX3gJmPa1TqXy72P1fqMdc3dWd6x4nBoDYpyAwC9U9FqPYaqvZ6g67N1B4Yhup6GxsfdtbmmP+K1p1r4nSoLhif0ENZ/7+nE//Lqv+fWv3lco/XH16q1MQuf0YcDqljTESgB7uzf9xgjddoMDx6gkKkN+i/4ahwl+IjzZ7V+KhwxfuDcnxUmH99/WWzjdPhCJzdWlHtP/u19g/Desueaq8qa3yqqPLWBXT/Hwb1/yio9pp/MNSG9xr/Y6/PMIcIRIQpOtyl6AhzmEB0hEvREWHmcnjturDA851i3RrRI6l5NvbZ/PtYfbbUqFGjdMEFF+iZZ56RJPl8PqWnp+vuu+/W/ffff1L7adOmqaysTG+99VZg3ejRozV8+HAtWLDglJ/X1s+WAppL7aGV2r/Sa3swTieM1b72xL/86+Yn/p+6N7gXzGfIW+//PIPn/vX+3pEwl1PhrpPHM9Uuh/vHRoW7zPFPtX9M1z/EVntoTSesMwKH3ozAj2i4y6nwMPP93GH+x/6p7rFD4WFOeap9dWGysnaqe1y3vm5dVY1PLn8PlcvhkNNpHm40x4HVrjPnLmftsjk+zHVi25PamfPaHrD6hzDd9Q9lhrsCz7nDgntOnA5H0NiwE8eF1fYQ1R9H5qnxqdRTozL/VFJZozKPV6WeapV6vCrzB+raNubcq6oarz8EBIfllhYd4VJiVLgSoyOUFBOuxKgIJUaHKzE6XEnREUqICpfL6dDR0iodLvXoSIlHh0vNw+hHSj06WlYV0nrbooz0RC2bfVGzvmebOVuqqqpKmzdv1ty5cwPrnE6nJkyYoOzs7AZfk52drfvuuy9o3cSJE7V06dIG23s8Hnk8nsDj4uLib184YAMOh0MRYWfXq1T72nZ/naNIqXOc2+oq2jzDMINtVb3ejBMPp9WuPzFUnJgxTvx73ZAUHe4yg0x0uBKiw+UO+3aXp6jx+nSsvEpHSqp0pF7oKayoVrjTEQiPgcNu4U5FuE4+ZFsbNiuqvSqprFFxRbWKK6vrLZu9rcUVNSesr5ZhyDzT1X/SRf0TMNxhZu9JpH8sXmS4uewOdynM6VCYy6kIlzmv/UMhzP/HQbh/fbi/ncspVVabPcPlVTWqqPKq3D9koLyqxlz2rzPXm+vOSW74jN5QsTTcHDlyRF6vVykpKUHrU1JStHv37gZfk5+f32D7/Pz8BttnZWXpkUceaZ6CAQDNzuEwe+DCXU7FtIGsGOZy+i9hYb9D6XZh+z+75s6dq6KiosCUm5trdUkAAKAFWdpz06lTJ7lcLhUUFAStLygoUGpqaoOvSU1NPaP2brdbbncb+FMAAAA0C0t7biIiIjRixAitWrUqsM7n82nVqlXKzMxs8DWZmZlB7SVp5cqVjbYHAADti+Wngt93332aOXOmzj//fI0cOVJPP/20ysrKdOutt0qSZsyYoa5duyorK0uSdM899+iSSy7RU089pauvvlqvvvqqNm3apOeff97KrwEAAFoJy8PNtGnTdPjwYT300EPKz8/X8OHDtXz58sCg4ZycHDmddR1MF154oV5++WX94he/0M9//nP169dPS5cu5Ro3AABAUiu4zk2ocZ0bAADanjP5/bb92VIAAKB9IdwAAABbIdwAAABbIdwAAABbIdwAAABbIdwAAABbIdwAAABbIdwAAABbsfwKxaFWe83C4uJiiysBAACnq/Z3+3SuPdzuwk1JSYkkKT093eJKAADAmSopKVFCQkKTbdrd7Rd8Pp8OHjyouLg4ORyORtsVFxcrPT1dubm57fo2DWwHE9vBxHaow7YwsR1MbIc6LbUtDMNQSUmJunTpEnTPyYa0u54bp9Opbt26nXb7+Pj4dr+jSmyHWmwHE9uhDtvCxHYwsR3qtMS2OFWPTS0GFAMAAFsh3AAAAFsh3DTC7Xbr4YcfltvttroUS7EdTGwHE9uhDtvCxHYwsR3qtIZt0e4GFAMAAHuj5wYAANgK4QYAANgK4QYAANgK4QYAANgK4aYBzz77rHr27KnIyEiNGjVKGzdutLqkkJs3b54cDkfQNGDAAKvLanFr167VNddcoy5dusjhcGjp0qVBzxuGoYceekhpaWmKiorShAkT9MUXX1hTbAs61Xa45ZZbTto/rrzySmuKbUFZWVm64IILFBcXp+TkZE2ZMkV79uwJalNZWanZs2erY8eOio2N1dSpU1VQUGBRxS3jdLbDuHHjTtonZs2aZVHFLWf+/PkaNmxY4AJ1mZmZevfddwPPt4f9QTr1drB6fyDcnOC1117Tfffdp4cfflhbtmxRRkaGJk6cqEOHDlldWsgNHjxYeXl5gWndunVWl9TiysrKlJGRoWeffbbB55944gn98Y9/1IIFC/Txxx8rJiZGEydOVGVlZYgrbVmn2g6SdOWVVwbtH6+88koIKwyNNWvWaPbs2dqwYYNWrlyp6upqXXHFFSorKwu0+dGPfqR///vfWrx4sdasWaODBw/quuuus7Dq5nc620GSbr/99qB94oknnrCo4pbTrVs3Pf7449q8ebM2bdqkyy67TJMnT9bOnTsltY/9QTr1dpAs3h8MBBk5cqQxe/bswGOv12t06dLFyMrKsrCq0Hv44YeNjIwMq8uwlCRjyZIlgcc+n89ITU01nnzyycC6wsJCw+12G6+88ooFFYbGidvBMAxj5syZxuTJky2px0qHDh0yJBlr1qwxDMP89w8PDzcWL14caPP5558bkozs7GyrymxxJ24HwzCMSy65xLjnnnusK8pCSUlJxgsvvNBu94datdvBMKzfH+i5qaeqqkqbN2/WhAkTAuucTqcmTJig7OxsCyuzxhdffKEuXbqod+/euummm5STk2N1SZbat2+f8vPzg/aPhIQEjRo1ql3uH6tXr1ZycrL69++vO++8U0ePHrW6pBZXVFQkSerQoYMkafPmzaqurg7aJwYMGKDu3bvbep84cTvU+sc//qFOnTppyJAhmjt3rsrLy60oL2S8Xq9effVVlZWVKTMzs93uDyduh1pW7g/t7saZTTly5Ii8Xq9SUlKC1qekpGj37t0WVWWNUaNGadGiRerfv7/y8vL0yCOP6OKLL9aOHTsUFxdndXmWyM/Pl6QG94/a59qLK6+8Utddd5169eqlL7/8Uj//+c81adIkZWdny+VyWV1ei/D5fLr33nt10UUXaciQIZLMfSIiIkKJiYlBbe28TzS0HSTp+9//vnr06KEuXbros88+0//7f/9Pe/bs0b/+9S8Lq20Z27dvV2ZmpiorKxUbG6slS5Zo0KBB2rZtW7vaHxrbDpL1+wPhBg2aNGlSYHnYsGEaNWqUevTooddff1233XabhZWhNbjxxhsDy0OHDtWwYcPUp08frV69WuPHj7ewspYze/Zs7dixo12MPWtKY9vhjjvuCCwPHTpUaWlpGj9+vL788kv16dMn1GW2qP79+2vbtm0qKirSG2+8oZkzZ2rNmjVWlxVyjW2HQYMGWb4/cFiqnk6dOsnlcp00sr2goECpqakWVdU6JCYm6pxzztHevXutLsUytfsA+8fJevfurU6dOtl2/5gzZ47eeustffjhh+rWrVtgfWpqqqqqqlRYWBjU3q77RGPboSGjRo2SJFvuExEREerbt69GjBihrKwsZWRk6A9/+EO72x8a2w4NCfX+QLipJyIiQiNGjNCqVasC63w+n1atWhV0HLE9Ki0t1Zdffqm0tDSrS7FMr169lJqaGrR/FBcX6+OPP273+8fXX3+to0eP2m7/MAxDc+bM0ZIlS/TBBx+oV69eQc+PGDFC4eHhQfvEnj17lJOTY6t94lTboSHbtm2TJNvtEw3x+XzyeDztZn9oTO12aEjI9wfLhjK3Uq+++qrhdruNRYsWGbt27TLuuOMOIzEx0cjPz7e6tJD68Y9/bKxevdrYt2+f8dFHHxkTJkwwOnXqZBw6dMjq0lpUSUmJsXXrVmPr1q2GJON3v/udsXXrVuPAgQOGYRjG448/biQmJhrLli0zPvvsM2Py5MlGr169jIqKCosrb15NbYeSkhLjJz/5iZGdnW3s27fPeP/9943zzjvP6Nevn1FZWWl16c3qzjvvNBISEozVq1cbeXl5gam8vDzQZtasWUb37t2NDz74wNi0aZORmZlpZGZmWlh18zvVdti7d6/x6KOPGps2bTL27dtnLFu2zOjdu7cxduxYiytvfvfff7+xZs0aY9++fcZnn31m3H///YbD4TBWrFhhGEb72B8Mo+nt0Br2B8JNA/70pz8Z3bt3NyIiIoyRI0caGzZssLqkkJs2bZqRlpZmREREGF27djWmTZtm7N271+qyWtyHH35oSDppmjlzpmEY5ungDz74oJGSkmK43W5j/Pjxxp49e6wtugU0tR3Ky8uNK664wujcubMRHh5u9OjRw7j99ttt+QdAQ9tAkrFw4cJAm4qKCuOuu+4ykpKSjOjoaOPaa6818vLyrCu6BZxqO+Tk5Bhjx441OnToYLjdbqNv377GT3/6U6OoqMjawlvA//zP/xg9evQwIiIijM6dOxvjx48PBBvDaB/7g2E0vR1aw/7gMAzDCE0fEQAAQMtjzA0AALAVwg0AALAVwg0AALAVwg0AALAVwg0AALAVwg0AALAVwg0AALAVwg2Ads/hcGjp0qVWlwGgmRBuAFjqlltukcPhOGm68sorrS4NQBsVZnUBAHDllVdq4cKFQevcbrdF1QBo6+i5AWA5t9ut1NTUoCkpKUmSecho/vz5mjRpkqKiotS7d2+98cYbQa/fvn27LrvsMkVFRaljx4664447VFpaGtTmxRdf1ODBg+V2u5WWlqY5c+YEPX/kyBFde+21io6OVr9+/fTmm2+27JcG0GIINwBavQcffFBTp07Vp59+qptuukk33nijPv/8c0lSWVmZJk6cqKSkJH3yySdavHix3n///aDwMn/+fM2ePVt33HGHtm/frjfffFN9+/YN+oxHHnlEN9xwgz777DNdddVVuummm3Ts2LGQfk8AzSRkt+gEgAbMnDnTcLlcRkxMTND02GOPGYZh3pF61qxZQa8ZNWqUceeddxqGYRjPP/+8kZSUZJSWlgaef/vttw2n0xm4U3mXLl2MBx54oNEaJBm/+MUvAo9LS0sNSca7777bbN8TQOgw5gaA5S699FLNnz8/aF2HDh0Cy5mZmUHPZWZmatu2bZKkzz//XBkZGYqJiQk8f9FFF8nn82nPnj1yOBw6ePCgxo8f32QNw4YNCyzHxMQoPj5ehw4dOtuvBMBChBsAlouJiTnpMFFziYqKOq124eHhQY8dDod8Pl9LlASghTHmBkCrt2HDhpMeDxw4UJI0cOBAffrppyorKws8/9FHH8npdKp///6Ki4tTz549tWrVqpDWDMA69NwAsJzH41F+fn7QurCwMHXq1EmStHjxYp1//vkaM2aM/vGPf2jjxo36y1/+Ikm66aab9PDDD2vmzJmaN2+eDh8+rLvvvls333yzUlJSJEnz5s3TrFmzlJycrEmTJqmkpEQfffSR7r777tB+UQAhQbgBYLnly5crLS0taF3//v21e/duSeaZTK+++qruuusupaWl6ZVXXtGgQYMkSdHR0Xrvvfd0zz336IILLlB0dLSmTp2q3/3ud4H3mjlzpiorK/X73/9eP/nJT9SpUyd973vfC90XBBBSDsMwDKuLAIDGOBwOLVmyRFOmTLG6FABtBGNuAACArRBuAACArTDmBkCrxpFzAGeKnhsAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGArhBsAAGAr/x8nwCQy7XXeBAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate loss curve\n",
    "plt.plot(results['epoch'], results['train_loss_bpr'], label='train')\n",
    "plt.plot(results['epoch'], results['test_loss_bpr'], label='test')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bWKDD6Q9CYC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "2bWKDD6Q9CYC",
    "outputId": "5b63dc87-33bb-4fb9-fd74-da317aad7d2b"
   },
   "outputs": [],
   "source": [
    "# Generate evaluation metrics plot\n",
    "plt.plot(results['epoch'], results['precision@k'], label='precision@k')\n",
    "plt.plot(results['epoch'], results['recall@k'], label='recall@k')\n",
    "plt.plot(results['epoch'], results['map@k'], label='map@k')\n",
    "plt.plot(results['epoch'], results['mrr@k'], label='mrr@k')\n",
    "plt.plot(results['epoch'], results['ndcg@k'], label='ndcg@k')\n",
    "plt.plot(results['epoch'], results['hit_rate@k'], label='hit_rate@k')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Performance')\n",
    "plt.title('Evaluation metrics')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9722b1de-2c2c-4e14-8746-b25facee2e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['epoch'] = results['epoch'].astype(int)\n",
    "results['train_loss_bpr'] = results['train_loss_bpr'].astype(float)\n",
    "results['test_loss_bpr'] = results['test_loss_bpr'].astype(float)\n",
    "results['precision@k'] = results['precision@k'].astype(float)\n",
    "results['recall@k'] = results['recall@k'].astype(float)\n",
    "results['map@k'] = results['map@k'].astype(float)\n",
    "results['mrr@k'] = results['mrr@k'].astype(float)\n",
    "results['ndcg@k'] = results['ndcg@k'].astype(float)\n",
    "results['hit_rate@k'] = results['hit_rate@k'].astype(float)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95b8154-eed0-4484-96ca-84d884ff837e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('../results/results_EuCoHT.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Collaboration Recommender 2.0 (Heterogeneous)",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
