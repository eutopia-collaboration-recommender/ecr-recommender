{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "zYPnKxIhFGVJ",
      "metadata": {
        "id": "zYPnKxIhFGVJ"
      },
      "source": [
        "# Collaboration recommender system - Baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "x7McZwR_FRta",
      "metadata": {
        "id": "x7McZwR_FRta"
      },
      "source": [
        "## **Setting up environment**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jX5i4Qjs7MIl",
      "metadata": {
        "id": "jX5i4Qjs7MIl"
      },
      "source": [
        "### **Package installation**\n",
        "\n",
        "Installing `torch` and `torch_geometric` libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZmnOJPqebGWOArun1rn4wEJr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 11116,
          "status": "ok",
          "timestamp": 1731225123567,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "ZmnOJPqebGWOArun1rn4wEJr",
        "outputId": "28f962e4-e7bc-47cd-d43b-69317e33ad1b",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Requirement already satisfied: torch==2.4.0 in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n",
            "Requirement already satisfied: torchvision==0.19.0 in /usr/local/lib/python3.10/dist-packages (0.19.0+cu121)\n",
            "Requirement already satisfied: torchaudio==2.4.0 in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (3.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0) (3.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.19.0) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.19.0) (10.4.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0) (12.6.77)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.0) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.0) (1.3.0)\n",
            "Collecting faiss-gpu==1.7.3\n",
            "  Downloading https://github.com/kyamagu/faiss-wheels/releases/download/v1.7.3/faiss_gpu-1.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (432.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m432.4/432.4 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip3 install torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cu121\n",
        "# Installation due to error: Faiss assertion 'err == CUBLAS_STATUS_SUCCESS' failed\n",
        "!pip install https://github.com/kyamagu/faiss-wheels/releases/download/v1.7.3/faiss_gpu-1.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "t4n7jKW9uiQE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 2210,
          "status": "ok",
          "timestamp": 1731225125772,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "t4n7jKW9uiQE",
        "outputId": "211fc49d-8ecb-4f93-85b1-1243ac44aea4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4.0+cu121\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import os\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "l5xNebKEDu-O",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5xNebKEDu-O",
        "outputId": "4488b49c-ec75-4065-865f-b02548bee84c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1731225142262,
          "user_tz": -60,
          "elapsed": 16498,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.4.0+cu121.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.10/dist-packages (2.1.2+pt24cu121)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.4.0+cu121.html\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.10/dist-packages (0.6.18+pt24cu121)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.26.4)\n",
            "Looking in links: https://data.pyg.org/whl/nightly/torch-2.4.0+cu121.html\n",
            "Requirement already satisfied: pyg-lib in /usr/local/lib/python3.10/dist-packages (0.4.0.dev20241031+pt24cu121)\n",
            "Collecting git+https://github.com/pyg-team/pytorch_geometric.git\n",
            "  Cloning https://github.com/pyg-team/pytorch_geometric.git to /tmp/pip-req-build-kj4kzg9o\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/pyg-team/pytorch_geometric.git /tmp/pip-req-build-kj4kzg9o\n",
            "  Resolved https://github.com/pyg-team/pytorch_geometric.git to commit f5c829344517c823c24abb08ce2fc7cf00ff29f7\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.7.0) (3.10.10)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.7.0) (2024.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.7.0) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.7.0) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.7.0) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.7.0) (3.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.7.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.7.0) (4.66.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.7.0) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.7.0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.7.0) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.7.0) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.7.0) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.7.0) (1.15.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.7.0) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric==2.7.0) (3.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.7.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.7.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.7.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.7.0) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric==2.7.0) (4.12.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->torch-geometric==2.7.0) (0.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install pyg-lib -f https://data.pyg.org/whl/nightly/torch-${TORCH}.html\n",
        "!pip install git+https://github.com/pyg-team/pytorch_geometric.git"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cD8tnTfC60X2",
      "metadata": {
        "id": "cD8tnTfC60X2"
      },
      "source": [
        "### **Loading libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "5okfWmvKEI3Z",
      "metadata": {
        "id": "5okfWmvKEI3Z",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1731225577241,
          "user_tz": -60,
          "elapsed": 953,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "# PyTorch imports\n",
        "from torch import Tensor\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Linear, BCEWithLogitsLoss\n",
        "\n",
        "# PyTorch Geometric imports\n",
        "import torch_geometric\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.loader import LinkNeighborLoader, NeighborLoader\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn.models.lightgcn import BPRLoss, LightGCN\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.utils import structured_negative_sampling\n",
        "from torch_geometric.metrics import (\n",
        "    LinkPredPrecision,\n",
        "    LinkPredRecall,\n",
        "    LinkPredMAP,\n",
        "    LinkPredMRR,\n",
        "    LinkPredNDCG\n",
        "    )\n",
        "\n",
        "# Other imports\n",
        "import io\n",
        "import datetime\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from google.cloud import bigquery\n",
        "from google.cloud import storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "X6kGtZ7RD7Y9",
      "metadata": {
        "id": "X6kGtZ7RD7Y9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1731225144221,
          "user_tz": -60,
          "elapsed": 4,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "801442cf-253f-4b57-d8de-73d4986c5ca5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA A100-SXM4-40GB\n",
            "2.4.0+cu121\n",
            "2.7.0\n",
            "Device: 'cuda'\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(torch.cuda.get_device_name(0))\n",
        "print(torch.__version__)\n",
        "print(torch_geometric.__version__)\n",
        "print(f\"Device: '{device}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bQ_xqBiFn97Q",
      "metadata": {
        "id": "bQ_xqBiFn97Q"
      },
      "source": [
        "### **Global variables**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9r1K6ezsn97Q",
      "metadata": {
        "id": "9r1K6ezsn97Q"
      },
      "outputs": [],
      "source": [
        "# Initiate global variables\n",
        "bq_client = bigquery.Client()\n",
        "storage_client = storage.Client()\n",
        "\n",
        "num_recommendations = 5 # Number of recommendations\n",
        "num_train = 0.8 # Percentage of data used for training\n",
        "learning_rate = 1e-2 # Learning rate\n",
        "num_epochs = 1000 # Number of epochs\n",
        "hidden_channels = 128 # Number of hidden channels\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ISUVX4hvFMKM",
      "metadata": {
        "id": "ISUVX4hvFMKM"
      },
      "source": [
        "## **Data preparation**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PUmNU6hf75k7",
      "metadata": {
        "id": "PUmNU6hf75k7"
      },
      "source": [
        "### **Loading data**\n",
        "\n",
        "When loading the data, we take into account only the articles, where at least one author comes from the EUTOPIA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ZMmIoKLMPOF",
      "metadata": {
        "id": "2ZMmIoKLMPOF"
      },
      "outputs": [],
      "source": [
        "# Get all authors data and value metrics about their collaboration\n",
        "author_query = f\"\"\"\n",
        "SELECT AUTHOR_SID,\n",
        "       PUBLICATION_COUNT\n",
        "FROM PROD.V_GRAPH_V3_NODE_AUTHOR\n",
        "\"\"\"\n",
        "author_df = bq_client.query(author_query).to_dataframe()\n",
        "\n",
        "\n",
        "# Get all edges between authors and co-authors\n",
        "coauthored_query = f\"\"\"\n",
        "SELECT AUTHOR_SID,\n",
        "       CO_AUTHOR_SID,\n",
        "       TIME\n",
        "FROM PROD.V_GRAPH_V3_EDGE_CO_AUTHORS\n",
        "\"\"\"\n",
        "coauthored_df = bq_client.query(coauthored_query).to_dataframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dZW9dtfeuhKT",
      "metadata": {
        "id": "dZW9dtfeuhKT"
      },
      "source": [
        "### Contiguous unique identifier for node: **author**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "S3vkAApdE7M9",
      "metadata": {
        "id": "S3vkAApdE7M9"
      },
      "outputs": [],
      "source": [
        "# Author: Map each unique MD5 hash to a contiguous unique integer ID\n",
        "unique_authors = author_df['AUTHOR_SID'].unique()\n",
        "author_id_map = {author: i for i, author in enumerate(unique_authors)}\n",
        "author_sid_map = {y: x for x, y in author_id_map.items()}\n",
        "# ---> Adjust all dataframes\n",
        "author_df['AUTHOR_NODE_ID'] = author_df['AUTHOR_SID'].map(author_id_map)\n",
        "coauthored_df['AUTHOR_NODE_ID'] = coauthored_df['AUTHOR_SID'].map(author_id_map)\n",
        "coauthored_df['CO_AUTHOR_NODE_ID'] = coauthored_df['CO_AUTHOR_SID'].map(author_id_map)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aZQQpLqCFeGK",
      "metadata": {
        "id": "aZQQpLqCFeGK"
      },
      "source": [
        "## **Homogeneous graph creation**\n",
        "First of all, we prepare the node features for articles. We first sort the article dataframe by node ID. We know that we have unique values in the article dataframe, i.e. one row per article and we can just sort it. Otherwise, we would need to create a unique mapping between article features and articles themselves. The sorting needs to match the node index that we will create later. After that, we also need to set up correct type (specifically, convert Pandas Int64 to int64, but we go for the lazy version and just convert all features to float64). At last, we exclude the `ARTICLE_SID` and `ARTICLE_NODE_ID` columns, because Torch can't work with strings.\n",
        "\n",
        "**TODO:**\n",
        "- Think about only including \"valuable\" partnerships/edges."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KHk6LU_su7-S",
      "metadata": {
        "id": "KHk6LU_su7-S"
      },
      "source": [
        "### Matrix X for node: **article**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e5ke0kkvLpg",
      "metadata": {
        "id": "7e5ke0kkvLpg"
      },
      "outputs": [],
      "source": [
        "# Article X\n",
        "# Sort article dataframe\n",
        "co_authors_edge_attr_columns = list(filter(lambda x: x not in ('AUTHOR_SID', 'CO_AUTHOR_SID', 'AUTHOR_NODE_ID', 'CO_AUTHOR_NODE_ID', 'TIME'), coauthored_df.columns))\n",
        "\n",
        "# Convert types\n",
        "edge_attr_co_authors = coauthored_df[co_authors_edge_attr_columns].astype('float64').values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XBN1GHNyvLPP",
      "metadata": {
        "id": "XBN1GHNyvLPP"
      },
      "source": [
        "### Matrix X for node: **author**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tg-GzYGtErQx",
      "metadata": {
        "id": "tg-GzYGtErQx"
      },
      "outputs": [],
      "source": [
        "# Author X\n",
        "# Sort author dataframe\n",
        "sorted_author_df = author_df.sort_values(by='AUTHOR_NODE_ID')\n",
        "# Exclude columns AUTHOR_SID, AUTHOR_NODE_ID\n",
        "author_x_columns = list(filter(lambda x: x not in ('AUTHOR_SID', 'AUTHOR_NODE_ID'), sorted_author_df.columns))\n",
        "\n",
        "# Convert types\n",
        "author_x = sorted_author_df[author_x_columns].astype('float64').values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6oizfRnsvjYx",
      "metadata": {
        "id": "6oizfRnsvjYx"
      },
      "source": [
        "### Edge index for edge: **(author, co_authors, author)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UqXKby3KFhqx",
      "metadata": {
        "id": "UqXKby3KFhqx"
      },
      "outputs": [],
      "source": [
        "# Add edge index: for edges corresponding to authors co-authoring articles (author to author connection)\n",
        "author_node_ids = torch.from_numpy(coauthored_df['AUTHOR_NODE_ID'].values)\n",
        "coauthor_node_ids = torch.from_numpy(coauthored_df['CO_AUTHOR_NODE_ID'].values)\n",
        "edge_index_co_authors = torch.stack([author_node_ids, coauthor_node_ids], dim=0)\n",
        "edge_time_co_authors = torch.from_numpy(np.array(coauthored_df['TIME'].values.astype('int64')))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mi3u5Xx0v5DB",
      "metadata": {
        "id": "mi3u5Xx0v5DB"
      },
      "source": [
        "### Data object"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PXBEBlOCFn34",
      "metadata": {
        "id": "PXBEBlOCFn34"
      },
      "source": [
        "After generating the initial node feature Numpy array, we create an instance of `HeteroData` class with two types of nodes corresponding to authors and articles and an edge denoting authors publishing articles.\n",
        "\n",
        "*Note: We also need to make sure to add the reverse edges from authors to aritcles in order to let a GNN be able to pass messages in both directions. We can leverage the `T.ToUndirected()` transform for this from PyG.*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_to_train_and_test(data, num_train=0.8):\n",
        "    time = data.edge_time\n",
        "    perm = time.argsort()\n",
        "    train_index = perm[:int(num_train * perm.numel())]\n",
        "    test_index = perm[int(num_train * perm.numel()):]\n",
        "\n",
        "    # Edge index\n",
        "    data.train_pos_edge_index = data.edge_index[:, train_index]\n",
        "    data.test_pos_edge_index = data.edge_index[:, test_index]\n",
        "\n",
        "    # Add negative samples to test\n",
        "    neg_edge_index_i, neg_edge_index_j, neg_edge_index_k = structured_negative_sampling(\n",
        "        edge_index=data.test_pos_edge_index,\n",
        "        num_nodes=data.num_nodes\n",
        "        )\n",
        "    data.test_neg_edge_index = torch.stack([neg_edge_index_i, neg_edge_index_k], dim=0)\n",
        "\n",
        "    # data.edge_index = data.edge_attr = data.edge_time = None\n",
        "    return data"
      ],
      "metadata": {
        "id": "d1_gvFOTCY_x"
      },
      "id": "d1_gvFOTCY_x",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0h15yaEpFo8x",
      "metadata": {
        "id": "0h15yaEpFo8x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1731225148962,
          "user_tz": -60,
          "elapsed": 7,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "7ec3bc05-70f1-4d4a-da13-82582e2893a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(node_id=[56233], edge_index=[2, 252269], edge_attr=[252269, 0], edge_time=[252269], x=[56233, 1], num_features=1, num_nodes=56233, train_pos_edge_index=[2, 201815], test_pos_edge_index=[2, 50454], test_neg_edge_index=[2, 50454])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "data = Data()\n",
        "\n",
        "# Save node indices:\n",
        "data.node_id = torch.arange(len(unique_authors))\n",
        "# Add edge 'co_authors'\n",
        "data.edge_index = edge_index_co_authors\n",
        "data.edge_attr = torch.from_numpy(edge_attr_co_authors).to(torch.float)\n",
        "data.edge_time = edge_time_co_authors\n",
        "\n",
        "# Set X for author nodes\n",
        "data.x = torch.from_numpy(author_x).to(torch.float)\n",
        "\n",
        "# Metadata about number of features and nodes\n",
        "data.num_features = data.x.shape[1]\n",
        "data.num_nodes = data.x.shape[0]\n",
        "\n",
        "# Feature normalization\n",
        "data = split_to_train_and_test(data)\n",
        "\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04vUews17zy8",
      "metadata": {
        "id": "04vUews17zy8"
      },
      "source": [
        "## Model training\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "model = LightGCN(num_nodes=data.num_nodes,\n",
        "    embedding_dim=hidden_channels,\n",
        "    num_layers=2).to(device)\n",
        "\n",
        "# Transfer to device\n",
        "data = data.to(device)\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
        "criterion_bcewll = BCEWithLogitsLoss().to(device)"
      ],
      "metadata": {
        "id": "nXNlqMGq9u93",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1731226249375,
          "user_tz": -60,
          "elapsed": 4,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "086c02fc-980e-475a-95a1-6e79998fff33"
      },
      "id": "nXNlqMGq9u93",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    model.train()\n",
        "\n",
        "    pos_edge_index = data.train_pos_edge_index\n",
        "    # Negative sampling\n",
        "    neg_edge_index_i, neg_edge_index_j, neg_edge_index_k = structured_negative_sampling(\n",
        "        edge_index=pos_edge_index,\n",
        "        num_nodes=data.num_nodes)\n",
        "    neg_edge_index = torch.stack([neg_edge_index_i, neg_edge_index_k], dim=0)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    edge_label_index = torch.cat([\n",
        "        pos_edge_index,\n",
        "        neg_edge_index,\n",
        "    ], dim=1)\n",
        "\n",
        "    pos_rank, neg_rank = model(pos_edge_index, edge_label_index).chunk(2)\n",
        "\n",
        "    # Calculate BPR loss\n",
        "    loss = loss_bpr = model.recommendation_loss(\n",
        "        pos_rank,\n",
        "        neg_rank,\n",
        "        node_id=edge_label_index.unique(),\n",
        "    )\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss = float(loss) * pos_rank.numel()\n",
        "    total_examples = pos_rank.numel()\n",
        "\n",
        "    # Cleanup\n",
        "    del pos_rank, neg_rank\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "    return  total_loss / total_examples\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test():\n",
        "    model.eval()\n",
        "\n",
        "    pos_edge_index = data.test_pos_edge_index\n",
        "    neg_edge_index = data.test_neg_edge_index\n",
        "\n",
        "    edge_label_index = torch.cat([\n",
        "        pos_edge_index,\n",
        "        neg_edge_index,\n",
        "    ], dim=1)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    pos_rank, neg_rank = model(pos_edge_index, edge_label_index).chunk(2)\n",
        "\n",
        "    loss = model.recommendation_loss(\n",
        "        pos_rank,\n",
        "        neg_rank,\n",
        "        node_id=edge_label_index.unique(),\n",
        "    )\n",
        "\n",
        "    total_loss = float(loss) * pos_rank.numel()\n",
        "    total_examples = pos_rank.numel()\n",
        "\n",
        "    # Cleanup\n",
        "    del pos_rank, neg_rank\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return total_loss / total_examples\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(k:int=20):\n",
        "    model.eval()\n",
        "    embs = model.get_embedding(data.train_pos_edge_index).to(device)\n",
        "    recalls = []\n",
        "\n",
        "    result = {\n",
        "        'precision@k': LinkPredPrecision(k=k).to(device),\n",
        "        'recall@k': LinkPredRecall(k=k).to(device),\n",
        "        'map@k': LinkPredMAP(k=k).to(device),\n",
        "        'mrr@k': LinkPredMRR(k=k).to(device),\n",
        "        'ndcg@k': LinkPredNDCG(k=k).to(device)\n",
        "        }\n",
        "\n",
        "    # Calculate distance between embeddings\n",
        "    logits = embs @ embs.T\n",
        "\n",
        "    # Exclude training edges\n",
        "    logits[data.train_pos_edge_index[0], data.train_pos_edge_index[1]] = float('-inf')\n",
        "\n",
        "    # Gather ground truth data\n",
        "    ground_truth = data.test_pos_edge_index\n",
        "\n",
        "    # Get top-k recommendations for each node\n",
        "    top_k_index = torch.topk(logits, k=k, dim=1).indices\n",
        "\n",
        "    # Update performance metrics\n",
        "    for metric in result.keys():\n",
        "      result[metric].update(\n",
        "          pred_index_mat=top_k_index,\n",
        "          edge_label_index=ground_truth)\n",
        "\n",
        "    # Cleanup\n",
        "    del embs, logits, ground_truth, top_k_index\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "4qloRMMtY3um",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1731226242635,
          "user_tz": -60,
          "elapsed": 944,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "4qloRMMtY3um",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "for epoch in range(1,  200):\n",
        "    train_loss = train()\n",
        "    test_loss = test()\n",
        "    scheduler.step(test_loss)\n",
        "    eval_result = evaluate(k=num_recommendations)\n",
        "\n",
        "    # Save results\n",
        "    epoch_result = {\n",
        "        'epoch': epoch,\n",
        "        'train_loss': train_loss,\n",
        "        'test_loss': test_loss,\n",
        "        'precision@k': eval_result['precision@k'].compute(),\n",
        "        'recall@k': eval_result['recall@k'].compute(),\n",
        "        'map@k': eval_result['map@k'].compute(),\n",
        "        'mrr@k': eval_result['mrr@k'].compute(),\n",
        "        'ndcg@k': eval_result['ndcg@k'].compute()\n",
        "    }\n",
        "    results.append(epoch_result)\n",
        "\n",
        "    # Log results\n",
        "    if epoch % 50 == 0:\n",
        "        # Log model performance\n",
        "        formatted_str = ', '.join([f'{key}: {epoch_result[key]:.4f}' for key in epoch_result.keys()])\n",
        "        print(formatted_str)\n",
        "\n",
        "\n",
        "results = pd.DataFrame(results)"
      ],
      "metadata": {
        "id": "HD0H7fh5Y7Tb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98f99a0c-28a8-48f6-b8e8-d8e89ec113cd",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1731226325924,
          "user_tz": -60,
          "elapsed": 74816,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "HD0H7fh5Y7Tb",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 50.0000, train_loss: 0.0204, test_loss: 0.2463, precision@k: 0.0269, recall@k: 0.0330, map@k: 0.0280, mrr@k: 0.0551, ndcg@k: 0.0393\n",
            "epoch: 100.0000, train_loss: 0.0061, test_loss: 0.2157, precision@k: 0.0294, recall@k: 0.0365, map@k: 0.0313, mrr@k: 0.0634, ndcg@k: 0.0439\n",
            "epoch: 150.0000, train_loss: 0.0033, test_loss: 0.2082, precision@k: 0.0306, recall@k: 0.0382, map@k: 0.0334, mrr@k: 0.0676, ndcg@k: 0.0465\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model evaluation"
      ],
      "metadata": {
        "id": "CIzjEI3R-eY-"
      },
      "id": "CIzjEI3R-eY-"
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate loss curve\n",
        "plt.plot(results['epoch'], results['train_loss'], label='train')\n",
        "plt.plot(results['epoch'], results['test_loss'], label='test')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss Curve')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JHmrYAoF-dWh",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1731225527642,
          "user_tz": -60,
          "elapsed": 3,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "JHmrYAoF-dWh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate evaluation metrics plot\n",
        "plt.plot(results['epoch'], results['precision@k'], label='precision@k')\n",
        "plt.plot(results['epoch'], results['recall@k'], label='recall@k')\n",
        "plt.plot(results['epoch'], results['map@k'], label='map@k')\n",
        "plt.plot(results['epoch'], results['mrr@k'], label='mrr@k')\n",
        "plt.plot(results['epoch'], results['ndcg@k'], label='ndcg@k')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Performance')\n",
        "plt.title('Evaluation metrics')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iW4LNHk7rDuE",
        "executionInfo": {
          "status": "aborted",
          "timestamp": 1731225527642,
          "user_tz": -60,
          "elapsed": 2,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "iW4LNHk7rDuE",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Collaboration Recommender (BASELINE).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}