{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "zYPnKxIhFGVJ",
   "metadata": {
    "id": "zYPnKxIhFGVJ"
   },
   "source": [
    "# Build heterogeneous dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "x7McZwR_FRta",
   "metadata": {
    "id": "x7McZwR_FRta"
   },
   "source": [
    "## Setting up environment\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jX5i4Qjs7MIl",
   "metadata": {
    "id": "jX5i4Qjs7MIl"
   },
   "source": [
    "### Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5okfWmvKEI3Z",
   "metadata": {
    "id": "5okfWmvKEI3Z"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))\n",
    "\n",
    "import pickle\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from box import Box\n",
    "\n",
    "from util.postgres import create_sqlalchemy_engine\n",
    "from util.heterogeneous.dataset import DatasetEuCoHT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bQ_xqBiFn97Q",
   "metadata": {
    "id": "bQ_xqBiFn97Q"
   },
   "source": [
    "### Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9r1K6ezsn97Q",
   "metadata": {
    "id": "9r1K6ezsn97Q"
   },
   "outputs": [],
   "source": [
    "# -------------------- GLOBAL VARIABLES --------------------\n",
    "PATH_TO_CONFIG_FILE = '../config.yaml'\n",
    "\n",
    "# -------------------- LOAD CONFIGURATION --------------------\n",
    "# Load the configuration file\n",
    "config = Box.from_yaml(filename=PATH_TO_CONFIG_FILE)\n",
    "\n",
    "num_train = 0.7             # Percentage of data used for training\n",
    "dataset_save_filepath = '../data/dataset_heterogeneous.pkl'\n",
    "dataset_save_filepath_prefix = '../data/dataset_heterogeneous'\n",
    "target_edge_type = ('author', 'co_authors', 'author')\n",
    "target_node_type = 'author'\n",
    "num_bootstrap = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ISUVX4hvFMKM",
   "metadata": {
    "id": "ISUVX4hvFMKM"
   },
   "source": [
    "## Data preparation\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2d66ba3-0e0f-410f-8818-b9a310ab2304",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pg_engine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m author_node_id_map: \u001b[38;5;28mdict\u001b[39m\n\u001b[1;32m      4\u001b[0m author_id_map: \u001b[38;5;28mdict\u001b[39m\n\u001b[1;32m      5\u001b[0m dataset: DatasetEuCoHT \u001b[38;5;241m=\u001b[39m DatasetEuCoHT(\n\u001b[0;32m----> 6\u001b[0m     pg_engine\u001b[38;5;241m=\u001b[39m\u001b[43mpg_engine\u001b[49m, \n\u001b[1;32m      7\u001b[0m     num_train\u001b[38;5;241m=\u001b[39mnum_train,\n\u001b[1;32m      8\u001b[0m     target_edge_type\u001b[38;5;241m=\u001b[39mtarget_edge_type,\n\u001b[1;32m      9\u001b[0m     target_node_type\u001b[38;5;241m=\u001b[39mtarget_node_type\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     11\u001b[0m data, author_node_id_map, author_id_map \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mbuild_heterogeneous_graph()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pg_engine' is not defined"
     ]
    }
   ],
   "source": [
    "dpg_engine = create_sqlalchemy_engine(\n",
    "    username=config.POSTGRES.USERNAME,\n",
    "    password=config.POSTGRES.PASSWORD,\n",
    "    host=config.POSTGRES.HOST,\n",
    "    port=config.POSTGRES.PORT,\n",
    "    database=config.POSTGRES.DATABASE,\n",
    "    schema=config.POSTGRES.SCHEMA\n",
    ")\n",
    "\n",
    "# Build the homogeneous graph\n",
    "data: Data\n",
    "author_node_id_map: dict\n",
    "author_id_map: dict\n",
    "dataset: DatasetEuCoHT = DatasetEuCoHT(\n",
    "    pg_engine=pg_engine, \n",
    "    num_train=num_train,\n",
    "    target_edge_type=target_edge_type,\n",
    "    target_node_type=target_node_type\n",
    ")\n",
    "data, author_node_id_map, author_id_map = dataset.build_heterogeneous_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537a80c0-aadf-4a0d-903e-968c8b3b9dae",
   "metadata": {},
   "source": [
    "## Data preparation: Bootstrapped\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bf04523-f2b5-4e03-860b-42810a2f9508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying co-authorship edge data...\n",
      "Querying author nodes...\n",
      "Querying publishing edge data...\n",
      "Querying article nodes...\n",
      "Rows fetched 10000 for batch 0\n",
      "Rows fetched 10000 for batch 1\n",
      "Rows fetched 10000 for batch 2\n",
      "Rows fetched 10000 for batch 3\n",
      "Rows fetched 10000 for batch 4\n",
      "Rows fetched 10000 for batch 5\n",
      "Rows fetched 10000 for batch 6\n",
      "Rows fetched 10000 for batch 7\n",
      "Rows fetched 10000 for batch 8\n",
      "Rows fetched 10000 for batch 9\n",
      "Rows fetched 10000 for batch 10\n",
      "Rows fetched 10000 for batch 11\n",
      "Rows fetched 10000 for batch 12\n",
      "Rows fetched 10000 for batch 13\n",
      "Rows fetched 10000 for batch 14\n",
      "Rows fetched 10000 for batch 15\n",
      "Rows fetched 10000 for batch 16\n",
      "Rows fetched 10000 for batch 17\n",
      "Rows fetched 10000 for batch 18\n",
      "Rows fetched 10000 for batch 19\n",
      "Rows fetched 10000 for batch 20\n",
      "Rows fetched 10000 for batch 21\n",
      "Rows fetched 10000 for batch 22\n",
      "Rows fetched 10000 for batch 23\n",
      "Rows fetched 10000 for batch 24\n",
      "Rows fetched 10000 for batch 25\n",
      "Rows fetched 10000 for batch 26\n",
      "Rows fetched 10000 for batch 27\n",
      "Rows fetched 10000 for batch 28\n",
      "Rows fetched 10000 for batch 29\n",
      "Rows fetched 10000 for batch 30\n",
      "Rows fetched 10000 for batch 31\n",
      "Rows fetched 10000 for batch 32\n",
      "Rows fetched 10000 for batch 33\n",
      "Rows fetched 10000 for batch 34\n",
      "Rows fetched 10000 for batch 35\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "the first argument must be callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1199928/3312849535.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mnum_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mtarget_edge_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_edge_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mtarget_node_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_node_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthor_node_id_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthor_id_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_heterogeneous_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Before saving the dataset, we need to close the engine to connect to Postgres DB.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/eutopia-colllaboration/ecr-recommender/util/heterogeneous/dataset.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0;31m# Apply the mapping to the dataframes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;31m# For authors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0mauthor_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'author_node_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauthor_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'author_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthor_node_id_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0mco_authored_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'author_node_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mco_authored_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'author_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthor_node_id_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             \u001b[0mco_authored_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'co_author_node_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mco_authored_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'co_author_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthor_node_id_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m             \u001b[0mpublished_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'author_node_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpublished_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'author_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthor_node_id_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0;31m# For articles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0marticle_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'article_node_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marticle_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'article_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle_id_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/eutopia-colllaboration/ecr-recommender/.venv/lib/python3.12/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, func, na_action, **kwargs)\u001b[0m\n\u001b[1;32m  10459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10460\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10461\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10463\u001b[0;31m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10465\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10466\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: the first argument must be callable"
     ]
    }
   ],
   "source": [
    "for bootstrap_id in range(num_bootstrap):\n",
    "    pg_engine = create_sqlalchemy_engine(\n",
    "        username=config.POSTGRES.USERNAME,\n",
    "        password=config.POSTGRES.PASSWORD,\n",
    "        host=config.POSTGRES.HOST,\n",
    "        port=config.POSTGRES.PORT,\n",
    "        database=config.POSTGRES.DATABASE,\n",
    "        schema=config.POSTGRES.SCHEMA\n",
    "    )\n",
    "    # Build the homogeneous graph\n",
    "    data: Data\n",
    "    author_node_id_map: dict\n",
    "    author_id_map: dict\n",
    "    dataset: DatasetEuCoHT = DatasetEuCoHT(\n",
    "        pg_engine=pg_engine, \n",
    "        num_train=num_train,\n",
    "        target_edge_type=target_edge_type,\n",
    "        target_node_type=target_node_type\n",
    "    )\n",
    "    data, author_node_id_map, author_id_map = dataset.build_heterogeneous_graph()\n",
    "\n",
    "    # Before saving the dataset, we need to close the engine to connect to Postgres DB.\n",
    "    dataset.close_engine()\n",
    "    # Save the dataset\n",
    "    with open(f'{dataset_save_filepath_prefix}_b{bootstrap_id}.pkl', 'wb') as output:\n",
    "        pickle.dump(dataset, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a61cf8-ddf7-4143-ad8f-752491458d20",
   "metadata": {},
   "source": [
    "### Unit tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f511ef30-b386-42ee-9ac2-74b7caf29994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test: check that the number of elements in the positive edge index equals to the number of elements in the negative edge index\n",
    "# assert data.test_pos_edge_index.numel() == data.test_neg_edge_index.numel()\n",
    "# # Test: check that the number of elements in the training, positive edge index equals to <num_train> times all nodes\n",
    "# assert data.train_pos_edge_index.shape[1] == int(num_train * data.edge_index.shape[1])\n",
    "# # Test: check that the number of elements in the test, positive edge index equals to <1 - num_train> times all nodes\n",
    "# assert data.test_pos_edge_index.shape[1] == data.edge_index.shape[1] - int(num_train * data.edge_index.shape[1])\n",
    "\n",
    "# # Test: check that all edges are bidirectional\n",
    "# assert_bidirectional_edges(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621189b8-8b4e-403c-9a2c-323b1005bd04",
   "metadata": {},
   "source": [
    "### Save dataset to local file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "816115e1-4b95-4796-b192-bcfce389a8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the dataset\n",
    "with open(dataset_save_filepath, 'wb') as output:\n",
    "    pickle.dump(dataset, output, pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Collaboration Recommender 2.0 (Heterogeneous)",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
